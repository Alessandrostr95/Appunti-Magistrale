#+title: ADRC - Lesson 15
#+date: <2021-11-25>
#+teacher: Andrea Clementi
#+setupfile: ../../org-template/appunti.org
#+options: num:nil

* Majority Consensus
  Sia un grafo \(G = (\left[ n \right], E)\) ed una sua /colorazione iniziale/ \(\mathbb{x} : \left[ n \right] \rightarrow C \equiv \lbrace 0, 1 \rbrace\).
  Si vuole progettare un protocollo efficiente per il problema del =Majority Consensus=.
  Partendo dall'assunzione che la configurazione iniziale abbia un certo sbilanciamento $s$ (/bias/), l'obiettivo è quello di convergere ad una configurazione monocromatica dove ogni nodo
  è colorato col colore più popolare inizialmente.\\

  Più precisamente indichiamo con
  - \(x_v^t\) il colore del nodo $v$ al tempo $t$.
  - \(x^t(0) = \vert \lbrace v \in V | x_v^t = 0 \rbrace \vert = a_t\), ovvero il numero di nodi che al tempo $t$ sono nel colore 0.
  - \(x^t(1) = \vert \lbrace v \in V | x_v^t = 1 \rbrace \vert = b_t\), ovvero il numero di nodi che al tempo $t$ sono nel colore 1.
  - \(C_t \in \lbrace 0,1 \rbrace^n\) la colorazione di $G$ al tempo $t$.
  - assumendo che all'inizio la maggioranza ha colore 1 (\(x^0(1) > x^0(0)\)) definiamo il /bias/ (/sbilanciamento/) inizale la quantità
    \[
    x^0(1) = \frac{n}{2} + s_0 \implies s_0 = x^0(1) - \frac{n}{2}
    \]
  D'ora in poi faremo riferimento semplicemente ad $s$ come al /bias/ che dipende dal corrente contesto \(C_t\).\\

  Definiamo ora formalmente il problema del /\(\ell\)-Majority-Consenus Problem/
  #+begin_quote
  *Def.* (/\(\ell\)-Majority-Consenus Problem/)
  Dato un sistema distribuito \(G = (\left[ n \right], E)\), l'/\(\ell\)-Majority-Consenus Problem/ è definito tramite le seguenti proprità.
  Iniziando da una colorazione iniziale \(C_0\) con /bias/ \(s > \ell\), il sistema deve convergere ad uno stato stabile in cui tutti i nodi hanno adotatto il colore di maggioranza iniziale, ovvero
  arrivare a un tempo \(\tau\) tale che
  \[
  C_\tau = \lbrace \max{(a_0, b_0)} \rbrace^n
  \]
  #+end_quote
  
** Simple Sampling
   Consideraimo il problema del \(\ell\)-Majority-Consenus su un *grafo completo* \(G = K_n\), e senza perdita di generalità assumiamo che il colore di maggioranza iniziale sia 1, perciò avremo che \(b_0 > a_0\).\\
   Un protocollo abbastanza semplice è il *Simple Sampling*, nel quale ogni nodo campiona /u.a.r./ \(R > 1\) vicini (compreso se stesso) e decide che colore assumere in base alla maggioranza dei nodi che ha campionato.\\

   Per prima cosa consideriamo un caso in cui il /bias/ sia *molto grande*, del tipo \(s \geq \frac{n}{4}\).
   In questo caso avremo che \(b_0 \geq \frac{3}{4}n\).\\

   Indichiamo con $R$ il numero di sampling che fa un nodo $v$, e con \(R_a,R_b\) il numero di volte che campiona un nodo colorato di 0 e 1 rispettivamente.\\

   Diremo che l'evento /"$v$ ha successo"/ occorre se alla fine dei $R$ campionamenti $v$ deciderà di passare al colore di maggioranza, ovvero se \(R_b > R_a\).\\

   Sia la v.a. binaria \(Y_i^v\) che vale 1 se $v$ campiona un nodo con colore 1 al tempo $i$, e 0 se ne campiona uno con colore 0.
   Tale v.a. avrà probabilità
   \[
   \mathcal{P}(Y_i^v = 1) = \frac{b_0}{n}
   \]
   e media
   \[
   \mathbb{E}\left[ Y_i^v \right] = \frac{b_0}{n}
   \]
   per ogni \(i = 1, 2, ..., R\).\\

   Per lineraità, la media del numero di volte che campiona un nodo con colore 1 (ovvero \(R_b\)) sarà
   \[
   \mathbb{E}\left[ Y^v \right] = \mathbb{E}\left[ R_b \right] = \sum_{i=1}^{R}\mathbb{E}\left[ Y_i^v \right] = R\frac{b_0}{n} \geq \frac{3}{4}R
   \]

   Si vuole calcolare in funzione di $R$ con quale probabilità $v$ ha successo, ovvero qual è la probabilità che \(\mathcal{P}(R_b \geq \frac{R}{2}) = \mathcal{P}(R_a < \frac{R}{2})\).
   Ovviamente, dato che vogliamo che vogliamo che il sampling dia un risultato  correttamente con _alta probabilità_, si vuole trovare un valore di $R$ per il quale
   \[
   \mathcal{P}(R_b \geq \frac{R}{2}) \geq 1 - \frac{1}{n^{\Omega(1)}}
   \]
   Per fare ciò, calcoliamo la probabilità dell'evento inverso.
   \begin{align*}
     \mathcal{P}\left( R_b < \frac{R}{2} \right)
     &= \mathcal{P}\left(R_b < \left(\frac{3}{4} - \frac{1}{4}\right) R \right)\\
     &= \mathcal{P}\left(R_b < \left(1 - \frac{1}{3}\right) \frac{3}{4}R \right)\\
     &= \mathcal{P}\left(R_b < \left(1 - \delta \right) \mathbb{E}\left[ R_b \right] \right)\\
     &\leq e^{-\beta R}
   \end{align*}

   Ponendo \(R = c\log{n}\), per un certo \(c > 0\) tale che \(c \beta > 1\), avremo ottenuto l'alta probabilità
   \[
   \mathcal{P}\left( R_b \geq \frac{c \log{n}}{2} \right) \geq 1 - \frac{1}{n}
   \]

   Se invece volessimo che questo risultato rimanga con alta probabilità per _tutti_ gli $n$ nodi e necessario scegleire un $c$ tale che \(c\beta > 2\), infatti
   \[
   \mathcal{P}(\mbox{"insuccesso"}) = \mathcal{P}(\bigcup_{v \in V} Y^v < \frac{c\log{n}}{2}) \leq \sum_{v \in V} \mathcal{P}(Y^b < \frac{c\log{n}}{2}) \leq \frac{1}{n}
   \]

   Perciò, se il /bias/ è molto grande \(s \in \Theta(n)\), con un numero *logaritmico* di campionamenti è possibile fare una buona stima con alta probabilità.
   Però non è vero il contrario.\\
   
   Se per esempio consideriamo un /bias/ di \(s \in \Theta(\sqrt{n\log{n}}) \in o(n)\), non basta un numero logaritmico di /sample/[fn:1], per avere l'alta probabilità.
   In questo caso è possibile dimostrare che si necessitano \(\Theta(\sqrt{n\log{n}})\) /sample/, il quale numero è *esponenzialmente* puù grande di \(\Theta(\log{n})\).

** Swarm Intelligence - k-Majority Protocol
   Un modo più efficiente per fare una statistica precisa della maggioranza è quello di sfruttare la /conoscenza/ degli altri nodi (*intelligenza di massa*, o *swarm intelligence*).
   L'idea è quella di campionare un certo numero di nodi /u.a.r./, e invece di cambiare colore in accordo alla loro colorazione iniziale, bisogna cambiare colore in base a ciò che la maggior parte dei nodi
   cambionati ritengono il colore di maggioranza.\\

   In poche parole, ad ogni tempo \(t \geq 0\), ogni nodo campio $k$ nodi /u.a.r./, ed aggiorna il suo colore in base al colore di maggioranza che ha campionato.\\

   La differenza col =Simple Sampling= sta nel fatto che mentre prima ogni nodo vaceva $R$ campionamenti sulla colorazione iniziale e poi prendeva una decisione finale, adesso invece ogni nodo _cambia_ stato ad ogni tempo $t$
   e quindi il campionamento è fatto in base alla colorazione del grafo al tempo \(t - 1\).\\

   Campionare i colori al tempo precedente sostanzialmente consiste nello sfruttare le conoscenze pregresse dei campionamenti fatti dagli altri nodi.
   Tale protocollo è noto come (/\(k\)-Majority Protocol/)

   #+begin_quote
   *Def.* (/\(k\)-Majority Protocol/)
   Nel /\(k\)-Majority Protocol/, in breve \(k\)-MAJ, ad ogni /time slot/ ogni nodo _campiona_ /u.a.r./ $k$ tra i suoi vicini (compreso se stesso) e si colora del colore di maggioranza che osserva.
   Il protocollo termina quando tutti i nodi sono dello stesso colore.
   #+end_quote

*** 1-MAJ
    È faciel dimostrare che la versione del \(k\)-MAJ con \(k = 1\) è molto poco efficiente, ovvero convergerà molto lentamente nello stato finale desiderato.
    Per dimostrarlo, basta dimostrare che mediamente ad ogni time slot il /bias/ s rimane uguale al /bias/ al tempo precedente.\\

    Sia \(s_t = b_t - \frac{n}{2}\) il valore del /bias/ al tempo $t$, e sia la v.a. \(s_{t+1}\) che indica il valore del /bias/ a tempo \(t + 1\).
    Siano inoltre le v.a. binarie \(X_1, ..., X_n\) tali che \(X_i = 1\) se il nodo \(v_i\) campiona un nodo colorato di 1 al tempo $t$ e quindi al tempo \(t + 1\) si colore di 1, 0 altrimenti, per ogni \(v_i \in V\).
    _Sapendo_ che \(b_t = n/2 + s_t\), tali variabili avranno probabilità
    \[
    \mathcal{P}(X_i = 1 | s_t) = \frac{b_t}{n}
    \]
    e media
    \[
    \mathbb{E}\left[ X_i | s_t \right] = \frac{b_t}{n} = \frac{\frac{n}{2} + s_t}{n} = \frac{1}{2} + \frac{s_t}{n}
    \]

    Sia quindi \(b_{t+1} = X_1 + ... + X_t\) il numero di nodi che hanno colore 1 al tempo \(t + 1\), con media
    \[
    \mathbb{E}\left[ b_{t+1} | s_t \right] = \sum_{i = 1}^{n} \mathbb{E}\left[ X_i | s_t \right] = \frac{n}{2} + s_t
    \]
    Ciò implica che \(s_{t+1}\) in madia varrà
    \[
    \mathbb{E}\left[ s_{t+1} | s_t \right] = \mathbb{E}\left[ b_{t+1} | s_t \right] - \frac{n}{2} = s_t
    \]

*** 3-MAJ
    *[DA FINIRE]*
    
[fn:1] campionamenti.
