<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it">
<head>
<!-- 2022-03-25 ven 13:22 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>ML - Lesson 05</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Alessandro Straziota" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" href="/appunti.css" />
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2020 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="h" href=""> UP </a>
 |
 <a accesskey="H" href="/"> HOME </a>
</div><div id="content">
<h1 class="title">ML - Lesson 05</h1>
<div id="table-of-contents">
<h2>Indice</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgddddd05">Loss e Training</a>
<ul>
<li><a href="#orgeac363e">Funzioni convesse</a>
<ul>
<li><a href="#orgac3dcb5">Quadratic Loss</a></li>
<li><a href="#orgfe68ef0">Absolute Loss</a></li>
<li><a href="#org5f22e5f">Huber Loss</a></li>
<li><a href="#orgf61705c">0/1 Loss.</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-orgddddd05" class="outline-2">
<h2 id="orgddddd05">Loss e Training</h2>
<div class="outline-text-2" id="text-orgddddd05">
<p>
Richiamando quanto visto nella <a href="./03.html">lezione 3</a>, la <i>funzione loss</i> \(L : \mathscr{Y} \times \mathscr{Y} \to \mathbb{R}\) misura per ogni coppia di valori target \(y_1, y_2\) il <b>costo</b> o <b>errore</b> di \(y_2\) rispetto a \(y_1\).
Nel nostro caso, nell'<b>apprendimento supervisionato</b> si cerca di misurare la <b>qualità</b> di un predittore \(h\) tramite una funzione di rischio \(\mathscr{R}\), ponendola semplicemente pari alla funzione di loss
\[
  \mathscr{R}(h(x), t) = L(h(x), t)
  \]
</p>

<p>
Purtroppo normalmente non abbiamo un a disposizione l'intera relazione tra ogni elemento \(x\) e i rispettivi traget \(t\).
In realtà abbiamo questa relazione solamente per un dato sottoinsieme, il training set \(\mathscr{T} \subseteq \mathscr{X} \times \mathscr{Y}\).
Perciò, ciò che si fa è calcolare il cosidetto <b>rischio empirico</b>
\[
  \overline{\mathscr{R}}_{\mathscr{T}}(h) = \frac{1}{\vert \mathscr{T} \vert} \sum_{(x,t) \in \mathscr{T}} L(h(x), t)
  \]
Ciò provvede a una misura di qualità di un predittore \(h\) rispetto ai dati in possesso.<br />
</p>

<p>
Perciò il problema dell'apprendimento automatico si riduce alla ricerca di una funzione \(h\) in uno spazio di funzioni \(\mathscr{H}\),
la quale <b>minimizza</b> la funzione di rischio empirico rispetto al dato training set.<br />
</p>

<p>
Dato che \(\mathscr{H}\) potrebbe essere uno spazio troppo grande da esplorare, in genere si riduce \(\mathscr{H}\) a una famiglia più piccola di funzioni, possibilmente caratterizzate da un <b>vettore di parametri</b> \(\theta \in \mathbb{R}^d\).
A questo punto la ricerca si riduce alla ricerca di <b>parametri</b> che fanno in modo che la funzione \(h_{\theta}\) minimizza la funzione loss.
\[
  \overline{\mathscr{R}}_{\mathscr{T}}(h_{\theta}) = \frac{1}{\vert \mathscr{T} \vert} \sum_{(x,t) \in \mathscr{T}} L(h_{\theta}(x), t)
  \]
</p>

<p>
Per pulizia di notazione, poniamo \(\vert \mathscr{T} \vert = n\) e consideriamo il vettore di parametri \(\theta\) che minimizza la somma
\[
  \sum_{i = 1}^{n} L(h_{\theta}(x_i), t_i)
  \]
tanto è equivalente.<br />
</p>

<p>
Dopodiché poniamo tutto in funzione del solo \(\theta\), definendo la famiglia di funzioni
\[
  L_i(\theta) = L(h_{\theta}(x_i), t_i)
  \]
</p>

<p>
Perciò possiamo dire (in maniera più pulita) che vogliamo trovare il punto \(\theta\) che minimizza la funzione
\[
  \mathscr{L}(\theta, \mathscr{T}) = \sum_{i = 1}^{n} L_i(\theta)
  \]
Ovvero abbiamo riscritto la funzione di rischio empirico come una nuova funzione di loss \(\mathscr{L}\) rispetto al solo parametro \(\theta\),
la quale a sua volta è la somma delle \(n\) funzioni di loss \(L_i(\theta)\).
In breve
\[
  \overline{\mathscr{R}}_{\mathscr{T}}(h_{\theta}) =
  \frac{1}{\vert \mathscr{T} \vert} \sum_{(x,t) \in \mathscr{T}} L(h_{\theta}(x), t)
  \propto \sum_{i = 1}^{n} L_i(\theta)
  \]
<br />
</p>

<p>
Abbiamo visto che gli approcci <b>analitici</b> alla ricerca di punti di minimo globale, come per esempio trovare quando il gradiente si annulla, hanno delle serie problematiche.
Infatti, quando il gradiente si annulla in:
</p>
<ul class="org-ul">
<li>punti di minimo <b>locale</b> (e non globale).</li>
<li>in punti di <b>sella</b>.</li>
<li>punti di <b>flesso</b>.</li>
</ul>

<p>
Perciò abbiamovisto che una soluzione migliore è quella di approcciare il problema tramite <b>metodi numerici</b>, come per esempio con la <b>discesa del gradinte</b>.
Alcune problematiche di questo approccio sono:
</p>
<ul class="org-ul">
<li>ci consente di trovare punti di minimo locale, i quali dipendono dal punto in cui partiamo con la ricerca.</li>
<li>il calcolo dei gradienti ad ogni passo potrebbe essere dispendioso se il training set è molto grande.</li>
<li>potrebbe convergere troppo lentamente.</li>
<li>la funzione potrebbe non essere derivabile in tutti punti.</li>
</ul>

<p>
Perciò l'approccio che generalmente si sfrutta, è quello di scegleiere adeguatamente la funzione di loss \(\mathscr{L}\) in modo tale che:
</p>
<ul class="org-ul">
<li>ha un solo punto di minimo.</li>
<li>oppure ha molteplici punti di minimo, che però approssimano abbastanza bene quello globale.</li>
<li>sia derivabile in tutti i punti.</li>
<li>non abbia punti di sella o di flesso.</li>
<li>sia facile calcolare il gradiente.</li>
</ul>
</div>

<div id="outline-container-orgeac363e" class="outline-3">
<h3 id="orgeac363e">Funzioni convesse</h3>
<div class="outline-text-3" id="text-orgeac363e">
<p>
Un insieme di punti \(S \subset R^d\) si dice <b>convesso</b> <span class="underline">se e solo se</span> per ogni coppia di punti \(x_1, x_2 \in S\) e per ogni \(\lambda \in (0,1)\), avremo che
\[
   \lambda x_1 + (1 - \lambda)x_2 \in S
   \]
</p>


<div class="figure">
<p><img src="../images/ml-lesson5-img1.png" alt="ml-lesson5-img1.png" style="max-width:450px; width:100%" />
</p>
<p><span class="figure-number">Figura 1: </span>Insieme convesso</p>
</div>

<p>
Allo stesso modo, una funzione \(f\) è convessa <span class="underline">se e solo se</span> l'insieme di punti posti al di sopra della funzione è convesso, ovvero
\[
   f(\lambda x_1 + (1 - \lambda)x_2) \leq \lambda f(x_1) + (1 - \lambda)f(x_2)
   \]
</p>


<div class="figure">
<p><img src="../images/ml-lesson5-img2.png" alt="ml-lesson5-img2.png" style="max-width:450px; width:100%" />
</p>
<p><span class="figure-number">Figura 2: </span>Funzione convessa.</p>
</div>

<p>
Cerchiamo di capire perché dovremmo interessarci alle <i>funzioni convesse</i>.
Dalla teroe è noto che se una funzione \(f\) è convessa, allora <b>ogni</b> minimo glovale di \(f\) è anche un minimo globale.
Ancor più importante, se una funzione \(f\) è <b>strettamente</b> convessa, ovvero
f(&lambda; x<sub>1</sub> + (1 - &lambda;)x<sub>2</sub>) &lt; &lambda; f(x<sub>1</sub>) + (1 - &lambda;)f(x<sub>2</sub>)
allora esiste un <b>unico</b> minimo locale, il quale è anche un minimo globale.<br />
</p>

<p>
Perciò, se ponessimo la funzione \(\mathscr{L}\) in maniera che risulti <b>convessa</b> (o anche <b>strettamente convessa</b>)
basterebbe calcolare il punto \(\theta\) (o unico nel caso di strettamente convessa) in cui il gradiente si annulla
\[
   \nabla_{\theta} \mathscr{L}(\theta, \mathscr{T}) = 0
   \]
</p>

<p>
Purtroppo, essendo \(\mathscr{L}\) una funzione composta da una somma di altre funzioni, potrebbe non essere facile trovarne una convessa.
In questo caso ci viene in aiuto un altro risultato teorica importante:
</p>

<p class="verse">
La <b>combinzione lineare</b> di funzioni convesse (o strettamente convesse) è ancora una funzione convessa (o strettamente convessa).<br />
</p>

<p>
Perciò non è necessario cercare un \(\mathscr{L}\) convessa, ci basterà invece che \(L_i(\theta)\) sia convessa, in quanto
\[
   \mathscr{L}(\theta, \mathscr{T}) = \sum_{i = 1}^{n} L_i(\theta)
   \]
Perciò se \(L_i\) è una famiglia di funzioni convesse, allora anche \(\mathscr{L}\) risulterà convessa.<br />
</p>
</div>

<div id="outline-container-orgac3dcb5" class="outline-4">
<h4 id="orgac3dcb5">Quadratic Loss</h4>
<div class="outline-text-4" id="text-orgac3dcb5">
<p>
Un primo esempio semplice di funzione convessa è una funzione <i>quadratica</i>.
Perciò possiamo considerare una funzione loss del tipo
\[
    L(y, t) = (y - t)^2
    \]
Questa funzione è detta <b>quadratic loss</b>.
</p>


<div id="org4681736" class="figure">
<p><img src="../images/ml-lesson5-img3.png" alt="ml-lesson5-img3.png" style="max-width:500px; width:100%" />
</p>
<p><span class="figure-number">Figura 3: </span>Quadratic loss.</p>
</div>

<p>
Avremo quindi che la funzione
\[
    \mathscr{L}(\theta, \mathscr{T}) = \sum_{i = 1}^{n} (h_{\theta}(x_i) - t_i)^2
    \]
risulta ancora essere una funzione convessa.<br />
</p>

<p>
Osservando la figura <a href="#org4681736">3</a> possiamo osservare che questa funzione da <i>troppa</i> rilevanza a valori anomali,
ovvero la misura di errore di una predizione \(y\) rispetto al valore ottimo \(t\) cresce troppo velocemente (in modo quadratico appunto).
</p>
</div>
</div>

<div id="outline-container-orgfe68ef0" class="outline-4">
<h4 id="orgfe68ef0">Absolute Loss</h4>
<div class="outline-text-4" id="text-orgfe68ef0">
<p>
Un'altra funzione convessa è la cosiddetta <b>absolute loss</b>.
\[
    L(y,t) = \vert t-y \vert
    \]
</p>


<div class="figure">
<p><img src="../images/ml-lesson5-img4.png" alt="ml-lesson5-img4.png" style="max-width:500px; width:100%" />
</p>
<p><span class="figure-number">Figura 4: </span>Absolute loss.</p>
</div>

<p>
Il vantaggio di tale funzione è che l'errore cresce in maniera <i>lineare</i> rispetto alla differenza tra \(t\) ed \(h(x)\), inoltre la derivata è facile da calcolare (è una costante).<br />
</p>

<p>
Un problema non indifferente è che esiste un <span class="underline">punto non derivabile</span>, quello <span class="underline">minimo</span>.
Purtroppo è <b>necessario</b> calcolare la derivata nel punto minimo durante la tecnica della discesa del gradiente,
in quanto ci consente di stabilire quando terminare la procedura.
Quindi non potendolo calcolare, non possiamo stabilire quando terminare il gradient descent.
</p>
</div>
</div>

<div id="outline-container-org5f22e5f" class="outline-4">
<h4 id="org5f22e5f">Huber Loss</h4>
<div class="outline-text-4" id="text-org5f22e5f">
<p>
Un buon compromesso è otteunto tramite la cosiddetta funzione <b>huber loss</b>, definita come segue
\[
    L(y,t) = \begin{cases}
      \frac12 (t - y)^2 &\vert t-y \vert \leq \delta\\
      \delta \left( \vert t - y \vert - \frac{\delta}{2} \right) &\vert t-y \vert > \delta
    \end{cases}
    \]
</p>


<div class="figure">
<p><img src="../images/ml-lesson5-img5.png" alt="ml-lesson5-img5.png" style="max-width:500px; width:100%" />
</p>
<p><span class="figure-number">Figura 5: </span>Huber loss.</p>
</div>

<p>
Tale funzione assume un andamento quadratico in un interno \(\delta\) di \(t\), e uno lineare al di fuori.
</p>
</div>
</div>


<div id="outline-container-orgf61705c" class="outline-4">
<h4 id="orgf61705c">0/1 Loss.</h4>
<div class="outline-text-4" id="text-orgf61705c">
<p>
Consideriamo un classico problema di <b>classificazione binaria</b>, in cui vogliamo l'insieme dei valori delle predizioni è \(\{ -1, 1 \}\).
Una funzione loss abbastanza naturale è quella che assegna 1 se \(y\) e \(t\) sono differenti, e 0 se sono uguali.
\[
    L(y,t) = \begin{cases}
      1 &\text{sgn}(t) \neq y\\
      0 &\text{sgn}(t) = y
    \end{cases}
    \]
dove la funzione \(\text{sgn}(x)\) vale 1 se \(x > 1\), e 0 altrimenti per ogni \(x \in \mathbb{R}\).<br />
</p>

<p>
Tale funzione può essere anche vista come la v.a.
\[
    \mathbf{1} \left[ ty < 0 \right]
    \]
che vale 1 se il prodotto \(ty < 0\), ovvero \(t\) e \(y\) sono differenti, e vale 0 se sono uguali.<br />
</p>

<p>
Questa funzione è nota come <b>0/1 loss function</b>.
</p>


<div class="figure">
<p><img src="../images/ml-lesson5-img6.png" alt="ml-lesson5-img6.png" style="max-width:500px; width:100%" />
</p>
<p><span class="figure-number">Figura 6: </span>0/1 loss.</p>
</div>

<p>
In questo caso avremo che la valutazione \(\mathscr{L}(\theta, \mathscr{T})\) è pari alla somma di tutte le <i>valutazioni errate</i> che fa il predittore \(h_{\theta}\) sui dati del training set \(\mathscr{T}\).<br />
</p>

<p>
Le problematiche di questa funzioni sono che:
</p>
<ul class="org-ul">
<li>la funzione non è convessa.</li>
<li>la funzione non è <b>smooth</b> (ovvero la derivata non è sempre definita).</li>
<li>la <span class="underline">derivata è sempre nulla</span>, perciò non posso applicare il gradient descent.</li>
<li>se il predittore \(h_{\theta}\) è una <span class="underline">funzione lineare</span>, ovvero \(h_{\theta}(x) = \theta_0 + \theta_1 x_1 + ... + \theta_d x_d\),
allora è noto che trovare il valore di \(\theta\) che minimzza la somma degli errori è un problema <b>NP-hard</b>!</li>
</ul>

<p>
Una idea è quindi quella di trovare una funzione simile alla 0/1, che preservi però tutte le proprietà a noi utili.
Queste funzioni sono dette <b>funzioni surrogate</b>.<br />
</p>

<p>
Una <i>funzione surrogata</i> approssima la 0/1 loss <b>sempre dall'alto</b>, e che risulta essere <b>convessa</b> e <b>smooth</b> (ovvero sempre derivabile).
</p>

<hr />
<p>
<b>[DA FINIRE]</b>
</p>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="date">Data: 2022-03-24 gio 00:00</p>
<p class="author">Autore: Alessandro Straziota</p>
<p class="email">Email: <a href="mailto:alessandrostr95@gmail.com">alessandrostr95@gmail.com</a></p>
<p class="date">Created: 2022-03-25 ven 13:22</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
