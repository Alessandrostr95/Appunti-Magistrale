<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it">
<head>
<!-- 2022-03-19 sab 22:05 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>ML - Lesson 03</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Alessandro Straziota" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" href="/appunti.css" />
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2020 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="h" href=""> UP </a>
 |
 <a accesskey="H" href="/"> HOME </a>
</div><div id="content">
<h1 class="title">ML - Lesson 03</h1>
<div id="table-of-contents">
<h2>Indice</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org0ad8cd7">Hypothesis set \(\mathscr{H}\)</a>
<ul>
<li><a href="#org03e3c67">Problema con \(\mathscr{H}\) grandi</a>
<ul>
<li><a href="#orgf5a13b4">Esempio</a></li>
</ul>
</li>
<li><a href="#org1ab5e5c">Tradeoff tra bias e varianza</a></li>
</ul>
</li>
<li><a href="#orgfc10019">Come calcolare \(h^*\)</a>
<ul>
<li><a href="#org91b081d">Gradient Descent</a></li>
<li><a href="#org9942755">Approcci probabilistici</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org0ad8cd7" class="outline-2">
<h2 id="org0ad8cd7">Hypothesis set \(\mathscr{H}\)</h2>
<div class="outline-text-2" id="text-org0ad8cd7">
<p>
Nella <a href="./02.html">lezione 2</a> abbiamo visto che il problema dell'apprendimento automatico supervisionato si riduce nel ricercare una funzione predittore \(h^*\) all'interno di una classe \(\mathscr{H}\) di funzioni (detta <b>hypothesis set</b>) che <b>minimizza</b> il rischio empirico dipendente dal training set \(\mathscr{T}\).
\[
   h^* = arg \min_{h \in \mathscr{H}} \mathscr{\overline{R}}_{\mathscr{T}}(h)
   \]
</p>

<p>
La scelta dell'insieme \(\mathscr{H}\) è uno dei problemi fondamentali del ML.
Infatti osserviamo che non possiamo scegliere \(\mathscr{H} = \mathscr{Y}^{\mathscr{X}}\) come l'insieme di tutte le funzioni da \(\mathscr{X}\) a \(\mathscr{Y}\), in quanto esso cresce in grandezza come \(\vert \mathscr{Y} \vert^{ \vert \mathscr{X} \vert }\).<br />
</p>

<p>
Perciò, per semplicità ci <b>restrigiamo</b> lo spazio ad un sottoinsieme proprio di \(\mathscr{Y}^{\mathscr{X}}\), sufficientemente piccolo.<br />
</p>

<p>
Sorgono spontanee le seguenti domande:
</p>
<ul class="org-ul">
<li>come influisce la struttura e la dimensione di \(\mathscr{H}\)?</li>
<li>come scegliere un \(\mathscr{H}\) che consenta di computare \(h^*\) in maniera efficiente?</li>
</ul>

<p>
Ciò che si fa generalmente è scegliere la classe \(\mathscr{H}\) sulla base di <b>conscenze pregresse</b> in merito al <i>task</i> che si vuole risolvere.
Avvolte invece, si sceglie la classe \(\mathscr{H}\) in maniera <b>sperimentale/empirica</b>, proseguendo per tentativi (guidati da intuizioni).<br />
</p>

<p>
Infine fissata la classe \(\mathscr{H}\), trovare l'\(h^*\) (ovvero un <span class="underline">minimo globale</span>) è un problema noto essere <i>computazionalmente difficile</i>.
In genere però si sceglie la struttura di \(\mathscr{H}\) in modo tale da poter semplificare la ricerca di \(h^*\).
Oppure si applicano metodi di <b>ricerca locale</b> per trovare dei <span class="underline">minimi locali</span>, che però sappiamo approssimano in maniera ragionevole \(h^*\).
Perciò il lavoro sperimentale nel ML consiste principalmente nel modificare opportunamente \(\mathscr{H}\).<br />
</p>

<p>
Per esempio, possiamo modificare \(\mathscr{H}\) modificando la <b>struttura delle funzioni</b> che la compongono, oppure modificando dei (meta-) <b>parametri</b> che la caratterizzano.
</p>
</div>

<div id="outline-container-org03e3c67" class="outline-3">
<h3 id="org03e3c67">Problema con \(\mathscr{H}\) grandi</h3>
<div class="outline-text-3" id="text-org03e3c67">
<p>
Supponiamo di avere larga libertà nel scegliere \(\mathscr{H}\).
Supponiamo di voler fare una <b>classificazione binaria</b> (per esempio classificare maschi e femmine), con training set \(\mathscr{T} = (X,t)\) e con una funzione Loss <b>binaria</b>
</p>
\begin{equation*}
L(y,t) = \begin{cases}
  0 &\mbox{se } y = t\\
  1 &\mbox{se } y \neq t
\end{cases}
\;\; \forall y \in \mathscr{Y}
\end{equation*}
<p>
ovvero che vale 1 se un oggetto \(x\) è classificato male, oppure 0.<br />
</p>

<p>
Assumiamo inoltre che la distribuzione dei target sia <b>uniforme</b>, ovvero che le due classi nella popolazione hanno più o meno la stessa dimensione (maschi e femmine sono più o meno lo stesso numero).
\[
    \forall x \in \mathscr{X} \;\; P(t_x = 1 \vert x) = P(t_x = 0 \vert x) = \frac12
    \]
</p>

<p>
Un classificatore \(h\) banale è il seguente:
</p>
\begin{equation*}
h(x) = \begin{cases}
  1 &\mbox{se } x = x_i \in X, t_i = 1\\
  0 &\mbox{altrimenti}
\end{cases}
\;\; \forall x \in \mathscr{X}
\end{equation*}
<p>
Ovvero \(h\) risponde correttamente per <span class="underline">tutte</span> le \(x\) che appartengono al training set, 0 in qualsiasi altro caso.<br />
</p>

<p>
Dal punto di vista del trainig set \(\mathscr{T}\) il predittore \(h\) è <i>ottimo</i> (in quanto risponde correttamente a tutti i valori di \(X\)), e infatti il rischio empirico risultante è 0.<br />
</p>

<p>
Quando invece applichiamo \(h\) su un campione casuale della popolazione, \(h\) sbaglierà praticamente per tutti i maschi che non sono in \(\mathscr{T}\).
Dato che abbiamo detto che maschi e femmine sono equamente distribuiti nella popolazione, avremo che il rischio di \(h\) è circa \(\approx \frac12\).<br />
</p>

<p>
Quando il predittore \(h\) dipende <span class="underline">troppo</span> dal training set, ovvero è molto preciso per \(\mathscr{T}\) ma si comporta male per la popolazione \(\mathscr{X}\) in generale, si parla del fenomeno dell'<b>overfitting</b>.<br />
</p>

<p>
Il problema che ci ha indotto a trovare una funzione \(h^*\) ottima per \(\mathscr{T}\) ma pessima per \(\mathscr{X}\) è stato appunto dare <b>troppa libertà</b> alla caratterizzazione di \(\mathscr{H}\).
Infatti se lo spazio delle iptesi \(\mathscr{H}\) è <i>troppo vasto</i>, allora rischio di trovare una funzione \(h^*\) ottima empiricamente, che però globalmente non va bene.<br />
</p>

<p>
Viceversa però potrebbe accadere una situaionz inversa.
Infatti se \(\mathscr{H}\) è troppo piccolo, rischio di trovare una funzione che è poco precisa anche per il training set \(\mathscr{H}\).
In questo caso si parla di <b>underfitting</b>.<br />
</p>

<p>
Perciò possiamo fare le seguenti osservazioni rispetto all'insieme delle ipotesi \(\mathscr{H}\):
</p>
<ul class="org-ul">
<li>se \(\mathscr{H}\) è troppo vasto (o <b>complesso</b>), potremmo andare in <b>overfitting</b>.
Infatti potremmo trovare un \(h^*\) <b>troppo specifica</b> per \(\mathscr{T}\), ma poco precisa rispetto a \(\mathscr{X}\) in generale.</li>
<li>se \(\mathscr{H}\) è troppo ristretto (o <b>semplice</b>), potremmo andare in <b>underfitting</b>.
Ovvero potrebbero non esistere funzioni \(h^*\) vadano mediamente bene ne per \(\mathscr{T}\) ne per \(\mathscr{X}\).</li>
</ul>

<p>
Morale:<br />
</p>
<p class="verse">
Non bisogna tenere né troppo né troppo poco del training set.<br />
</p>

<p>
Questo fenomeno è noto come <b>bias variance tradeoff</b> (tradeoff tra bias e varianza).
</p>
</div>

<div id="outline-container-orgf5a13b4" class="outline-4">
<h4 id="orgf5a13b4">Esempio</h4>
<div class="outline-text-4" id="text-orgf5a13b4">
<p>
Iniziamo considerando un primo insieme \(\mathscr{H}\) <i>molto ristretto</i>.
Per esempio l'insieme di tutte le <span class="underline">rette orizzontali</span>.
Certamenete esiste una retta che minimizza il rischio empirico, ovvero quella che minimizza la somma di tutti i singoli errori rispetto agli elementi nel training set \(\mathscr{T}\).
</p>


<div id="org9b3bf62" class="figure">
<p><img src="../images/ml-lesson3-img3.png" alt="ml-lesson3-img3.png" style="max-width:450px; width:100%" />
</p>
<p><span class="figure-number">Figura 1: </span>Retta orizzontale ottima per il training set.</p>
</div>

<p>
Guardando la <a href="#org9b3bf62">figura precedente</a> però possiamo osservare che si potrebbe fare decisamente molto meglio se solo considerassimo funzioni più articolate.
Infatti, al variare dal training set, qualsiasi retta ottima \(h^*\) risultante non varia molto, perché troppo poco specifica rispetto a \(\mathscr{T}\) (<b>underfitting</b>).<br />
</p>

<p>
Per fare meglio allora possiamo considerare un insieme più ampio, come per esempio l'insieme di <span class="underline">tutte le rette</span>.
Questo insieme contiene quello precedente, e quindi più espressivo.
Infatti in figura <a href="#orgf4deb7e">2</a> possiamo vedere che con una retta obliqua otteniamo un predittore \(h\) più specifico per \(\mathscr{T}\).
</p>


<div id="orgf4deb7e" class="figure">
<p><img src="../images/ml-lesson3-img4.png" alt="ml-lesson3-img4.png" style="max-width:450px; width:100%" />
</p>
<p><span class="figure-number">Figura 2: </span>Retta ottima per il training set.</p>
</div>

<p>
Rendendo ancora più variegato \(\mathscr{H}\), otteremo predittori sempre più precisi per \(\mathscr{T}\).
Per esempio ponendo \(\mathscr{H}\) come l'insieme dei polinomi di grado al più 2 (figura <a href="#org54a6353">3</a>), come l'insieme dei polinomi di grado al più 3 (figura <a href="#org2354d6e">4</a>), e così via&#x2026;
</p>


<div id="org54a6353" class="figure">
<p><img src="../images/ml-lesson3-img5.png" alt="ml-lesson3-img5.png" style="max-width:450px; width:100%" />
</p>
<p><span class="figure-number">Figura 3: </span>Parabola ottima per il training set.</p>
</div>


<div id="org2354d6e" class="figure">
<p><img src="../images/ml-lesson3-img6.png" alt="ml-lesson3-img6.png" style="max-width:450px; width:100%" />
</p>
<p><span class="figure-number">Figura 4: </span>Polinomio di terzo grado ottimo per il training set.</p>
</div>

<p>
Infine, se poniamo \(\mathscr{H}\) come l'insieme dei polinomi di grado \(n = \vert \mathscr{T} \vert\) otteremo un predittore \(h\) <b>ottimo</b>, per il quale il rischio empirico è 0.
Infatti sappiamo che esiste ed è unico un polinomio di grado al più \(n\) che tocca tutti gli \(n\) punti del training set sul piano.
</p>


<div class="figure">
<p><img src="../images/ml-lesson3-img7.png" alt="ml-lesson3-img7.png" style="max-width:450px; width:100%" />
</p>
<p><span class="figure-number">Figura 5: </span>Predittore empiricamente ottimo.</p>
</div>

<p>
Purtroppo però tale predittore \(h\) empiricamente ottimo è <span class="underline">troppo specifico</span> per \(\mathscr{T}\), mentre potrebbe comportarsi male per \(\mathscr{X}\) in generale (<b>overfitting</b>).
</p>
</div>
</div>
</div>

<div id="outline-container-org1ab5e5c" class="outline-3">
<h3 id="org1ab5e5c">Tradeoff tra bias e varianza</h3>
<div class="outline-text-3" id="text-org1ab5e5c">
<p>
Se prendo una classe \(\mathscr{H}\) composta da una sola funzione.
In questo caso limite avremo che il miglior predittore (unico) è <b>totalmente indipendente</b> dal training set \(\mathscr{T}\).
Facendo riferimento al precedente esempio, considerando l'insieme \(\mathscr{H}\) formato dalle sole rette orizzontoli, avevamo che al variare di \(\mathscr{T}\) i predittori ottimi non erano troppo diferenti tra di loro.
Ovvero, cambiando \(\mathscr{T}\), il predittore ottimo \(h^*\) non cambiava di molto la sua "forma".
Questo può essere interpretato come <b>poca dipendenza dal training set</b>.
Più precisamente, si parla di alto <b>bias</b> e bassa <b>varianza</b>.<br />
</p>

<p>
Viceversa, abbiamo visto che considero \(\mathscr{H}\) come l'insieme di polinomi di grado al più \(n = \mathscr{T}\), avrò un predittore ottimo \(h^*\) estremamente preciso, che per ogni elementro del training set \(\mathscr{T}\) predice esattamente il suo target associato.
Infatti, cambiando il \(\mathscr{T}\), il predittore ottimo \(h^*\) può cambiare di molto.
Questo viene interpretato invece come totale dipendenza dal training set.
In questo caso invece diremo che c'è alta <b>varianza</b> e basso <b>bias</b>.
</p>


<div class="figure">
<p><img src="../images/ml-lesson3-img1.png" alt="ml-lesson3-img1.png" style="max-width:450px; width:100%" />
</p>
<p><span class="figure-number">Figura 6: </span>Bias vs Varianza.</p>
</div>

<p>
Il rischio associato al <b>miglior predittore</b> \(h^*\) rispetto alla classe \(\mathscr{H}\) presa in considerazione può essere scritto come
\[
   \mathscr{R}(h^*) = \varepsilon_B + \varepsilon_V
   \]
</p>
<ul class="org-ul">
<li>\(\varepsilon_B\) è il minimo valore di rischio che un qualsiasi predittore \(h\) può ottenere.
Può anche essere visto come un errore derivante da presupposti errati nell'algoritmo di apprendimento.
Un elevato valore di \(\varepsilon_B\) può far sì che l'algoritmo di apprendimento che calcola \(h^*\) manchi le relazioni rilevanti tra le caratteristiche e i valori del traget che si desiderano predire (<b>underfitting</b>).
Questa quantità è anche nota come <b>bias</b>.</li>
<li>\(\varepsilon_V\) è la differenza tra il rischio minimo sopra indicato rispettp ad \(\mathscr{H}\) e il rischio associato al miglior predittore \(h^*\) rispetto al training set.
Può anche essere visto come un errore dovuto alla sensibilità a piccole fluttuazioni nel training set.
Un'elevato valore di \(\varepsilon_V\) può derivare da un algoritmo che modella il rumore casuale nei dati di addestramento (<b>overfitting</b>).
Questa quantità è anche nota come <b>varianza</b>.</li>
</ul>

<p>
La scelta di \(\mathscr{H}\) è soggetta a un <i>tradeoff</i> tra bias e varianza: un bias elevato può indurre a una bassa varianza, e viceversa.
</p>

<p>
Elevato bias e bassa varianza implicano che tutti i predittori che possono essere ottenuti da diversi training set tendono a comportarsi in modo simile, con un rischio simile (<i>bassa varianza</i>).
Tuttavia, tutti i predittori tendono a comportarsi male (<i>bias elevato</i>), poiché \(\mathscr{H}\) è troppo scarno per includere un predittore soddisfacente per il task considerato.
Ciò si traduce in <i>underfitting</i>.<br />
</p>

<p>
Bias basso e alta varianza implicano invece che molti predittori sono disponibili in \(\mathscr{H}\) e tra questi ne è solitamente disponibile uno particolarmente buono (<i>Bias basso</i>).
Tuttavia, è possibile ottenere predittori abbastanza diversi da diversi training set, il che implica che può facilmente accadere che, mentre si può ottenere un'ottima prestazione sul training set utilizzato,
il predittore risultante può comportarsi in modo abbastanza diverso e più scadente rispetto al migliore possibile, il che implica <i>overfitting</i>.
</p>


<div class="figure">
<p><img src="../images/ml-lesson3-img2.png" alt="ml-lesson3-img2.png" style="max-width:450px; width:100%" />
</p>
<p><span class="figure-number">Figura 7: </span>Tradeoff tra bias e varianza.</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgfc10019" class="outline-2">
<h2 id="orgfc10019">Come calcolare \(h^*\)</h2>
<div class="outline-text-2" id="text-orgfc10019">
<p>
Per trovare \(h^*\), iniziamo col definire le funzioni di \(\mathscr{H}\) in maniera <b>parametrica</b>, come per esempio l'insieme di tutti i polinomi di grado al più \(d\) per qualche costante \(d\) fissata.
In questa maniera le funzioni di \(\mathscr{H}\) possono essere visti come dei <i>punti \(d\)-dimensioni</i>, e perciò il problema dei trovare la funzione ottima \(h^*\) si riduce alla ricerca di un punto in uno spazio.
</p>

<p>
Inidichiamo quindi con \(\Theta\) il <b>domioni dei coefficienti</b> che parametrizzano le funzioni di \(\mathscr{H}\)
Perciò
\[
  \mathscr{H} = \{ h_{\theta} \vert \theta \in Theta \}
  \]
</p>

<p>
Una volta definito questo spazio vettoriale (parametrico), vogliamo trovare il punto \(\theta^* \in \Theta\) che minimizza il <i>rischio empirico</i> della relativa funzione.
Sia \(\theta^*\) equivale a
\[
  \theta^* = arg \min_{\theta \in \Theta} \overline{\mathscr{R}}_{\mathscr{T}}(h_{\theta})
  \]
</p>

<p>
Un primo approccio per cercare quindi i punti di minimo (quantomeno locali) della funzione \(\overline{\mathscr{R}}_{\mathscr{T}}\) nello spazio \(\Theta = \mathbb{R}^d\)
è applicando le classiche tecniche analitiche.<br />
</p>

<p>
Per esempio si potrebbe studiare quendo si annulla il gradiente della funzione \(\overline{\mathscr{R}}_{\mathscr{T}}\)
</p>
\begin{equation*}
  \nabla_{\theta} \overline{\mathscr{R}}_{\mathscr{T}}( h_{\theta} ) = \left(
  \begin{array}{c}
  \frac{\partial}{\partial \theta_1} \overline{\mathscr{R}}_{\mathscr{T}}( h_{\theta} )\\
  \frac{\partial}{\partial \theta_2} \overline{\mathscr{R}}_{\mathscr{T}}( h_{\theta} )\\
  \vdots\\
  \frac{\partial}{\partial \theta_d} \overline{\mathscr{R}}_{\mathscr{T}}( h_{\theta} )
  \end{array}
  \right) = 0
\end{equation*}

<p>
e ciò accade quando si annullano tutte le sue derivate parziali
\[
  \frac{\partial}{\partial \theta_i} \overline{\mathscr{R}}_{\mathscr{T}}( h_{\theta} ) = 0 \;\; \forall 1 \leq i \leq d
  \]
</p>

<p>
Purtroppo questo approccio non è sufficiente a trovare un minimo locale.
Infatti, il punto in cui il gradiente si annulla potrebbe combaciare con un <i>massimo</i> locale oppure con un <i>punto di sella</i>.<br />
</p>

<p>
Inoltre, se la funzione è parecchio complessa, trovare un punto che si avvicina ad un minimo globale potrebbe non essere semplice da fare con le tencniche analitiche.
Perciò nel ML si ricorre all'uso di tecniche <b>numeriche</b>, ovvero tramite i cosidetti <b>metodi iterativi</b>.<br />
</p>
</div>

<div id="outline-container-org91b081d" class="outline-3">
<h3 id="org91b081d">Gradient Descent</h3>
<div class="outline-text-3" id="text-org91b081d">
<p>
Il metodo iterativo più classico usato nel ML è il <b>gradient decent</b> (<b>discesa del gradiente</b>).
L'idea intuitiva è abbastanza semplice:
si calcola il gradiente, e si segue la direzione <i>"in discesa"</i> della funzione \(J(\theta)\) che si vuole minimizzare, e se non ci sono direzioni nelle quali si può scendere allora vuol dire che ci si trova già in un minimo locale.<br />
</p>

<p>
Più formalmente, la discesa del gradiente esegue la minimizzazione di una funzione \(J(\theta)\) tramite <b>aggiornamenti iterativi</b> del valore corrente di \(\theta\) (a partire da un valore iniziale \(\theta^{(0)}\))
in direzione opposta a quella specificata dal valore corrente del gradiente \(J'( \theta ) = \nabla_{\theta} J( \theta )\).
In direzione opposta la gradiente, altrimenti si "salirebbe", trovando massimi e non minimi locali.<br />
</p>


<div class="figure">
<p><img src="../images/ml-lesson3-img8.png" alt="ml-lesson3-img8.png" style="max-width:450px; width:100%" />
</p>
<p><span class="figure-number">Figura 8: </span>Gradient descent.</p>
</div>

<p>
Perciò fissato un punto iniziale \(\theta^{(0)}\), il processo al tempo \(k + 1\) si aggiorna nel seguente modo
\[
   \theta^{(k+1)} = \theta^{(k)} - \eta \nabla_{\theta} J( \theta^{(k)} )
   \]
il che si traduce per ogni singola componente \(\theta_i\) in
\[
   \theta^{(k+1)}_i = \theta^{(k)}_i - \eta \frac{\partial}{\partial \theta_i} J( \theta^{(k)}_i )
   \]
<br />
Nel nostro caso la funzione \(J(\theta)\) da minimizzare è il rischio empirico \(\overline{\mathscr{R}}_{\mathscr{T}}( h_{\theta} )\), perciò il metodo iterativo prende la seguente forma
</p>
\begin{align*}
  \theta^{(k+1)}_i
  &= \theta^{(k)}_i - \eta \frac{\partial}{\partial \theta_i} \frac{1}{\vert \mathscr{T} \vert} \sum_{(x,t) \in \mathscr{T}} L( h_{\theta^{(k)}}(x), t )\\
  &= \theta^{(k)}_i - \frac{\eta}{\vert \mathscr{T} \vert} \frac{\partial}{\partial \theta_i} \sum_{(x,t) \in \mathscr{T}} L( h_{\theta^{(k)}}(x), t )
\end{align*}

<p>
Questa particolare forma di graient descent generale, è anche nota come <b>batch gradient descent</b>, perché ad ogni passo dell'iterazione bisogna andare a calcolare l'intera funzione di rischio empirico sul training set.
Purtroppo però, quando il \(\mathscr{T}\) è molto grande, questa tecnica risulta essere molto dispendiosa.<br />
</p>

<p>
Una variante meno costosa, consiste partizinoare \(\mathscr{T}\) in \(m\) sottoinsiemi di dimensione costante, e ad ogni iterazione iterazione calcolare (a turnazione) il rischio empirico su un diverso sottoinsieme di \(\mathscr{T}\).
Questa tecnica è infatti nota come <b>batch gradient descent</b>.
</p>
</div>
</div>

<div id="outline-container-org9942755" class="outline-3">
<h3 id="org9942755">Approcci probabilistici</h3>
<div class="outline-text-3" id="text-org9942755">
<p>
<b>[ DA FINIRE ]</b>
</p>

<hr />
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="date">Data: 2022-03-17 gio 00:00</p>
<p class="author">Autore: Alessandro Straziota</p>
<p class="email">Email: <a href="mailto:alessandrostr95@gmail.com">alessandrostr95@gmail.com</a></p>
<p class="date">Created: 2022-03-19 sab 22:05</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
