<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it">
<head>
<!-- 2022-03-18 ven 13:03 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>ML - Lesson 02</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Alessandro Straziota" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" href="/appunti.css" />
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2020 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="h" href=""> UP </a>
 |
 <a accesskey="H" href="/"> HOME </a>
</div><div id="content">
<h1 class="title">ML - Lesson 02</h1>
<div id="table-of-contents">
<h2>Indice</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org97b5ede">Fondamenti del Machine Learning</a>
<ul>
<li><a href="#org36c0ebb">Supervised Learning</a></li>
<li><a href="#orgff3aef4">Unsupervised Learning</a></li>
<li><a href="#org8d7e9fa">Reinforcement Learning</a></li>
<li><a href="#org615e761">Definizioni</a></li>
<li><a href="#orgd316290">Prediction Risk</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org97b5ede" class="outline-2">
<h2 id="org97b5ede">Fondamenti del Machine Learning</h2>
<div class="outline-text-2" id="text-org97b5ede">
<p>
Intuitivamente, l'obiettivo principale del <b>Machine Learning</b> è quello di cercare di apprendere <b>caretteristiche comuni</b> (o <b>patterns</b>), sulla base di <b>esempi</b> (il <b>training set</b>),
in modo tale da ricavare un <b>modello</b> che ci consenta di fare <b>predizioni</b>.
Per predizione si intende inferire informazioni da dei dati in input, senza però che venga definito in maniera formale come estrapolare queste informazioni (altrimenti si definirebbe direttamente un agloritmo).<br />
</p>

<p>
Un <b>training set</b> composto da \(n\) items, è rappresentato come un insieme di vettori \(x_1, ..., x_n \in \mathbb{K}^d\) (per qualche dominio \(\mathbb{K}\) e costante \(d > 0\)).
Insieme agli \(n\) items, il training set è provvisto di un insieme di valroti \(t_1, ..., t_n\), detti valori <b>target</b>, che indicano le informazioni <i>reali</i> che siamo interessati a predire.
Come già accennato esso viene utilizzato per derivare un <b>modello di previsione</b> in grado di stimare il più precisamente possibile i target reali, che ovviamente dipenderà fortemente dal training set a disposizione.<br />
</p>


<div class="figure">
<p><img src="../images/ml-lesson2-img1.png" alt="ml-lesson2-img1.png" style="max-width:600px; width:100%" />
</p>
<p><span class="figure-number">Figura 1: </span>L'approccio può ossere applicato in maniera <b>iterativa</b>.</p>
</div>

<p>
Lo scopo finale è infine quello di predire il target con le migliori prestazioni possibili, sia in termini di <i>efficienza</i> che di <i>correttezza</i>.
</p>
</div>

<div id="outline-container-org36c0ebb" class="outline-3">
<h3 id="org36c0ebb">Supervised Learning</h3>
<div class="outline-text-3" id="text-org36c0ebb">
<p>
[descrizione informale]
</p>
</div>
</div>
<div id="outline-container-orgff3aef4" class="outline-3">
<h3 id="orgff3aef4">Unsupervised Learning</h3>
<div class="outline-text-3" id="text-orgff3aef4">
<p>
[descrizione informale]
</p>
</div>
</div>
<div id="outline-container-org8d7e9fa" class="outline-3">
<h3 id="org8d7e9fa">Reinforcement Learning</h3>
<div class="outline-text-3" id="text-org8d7e9fa">
<p>
[descrizione informale]
</p>
</div>
</div>

<div id="outline-container-org615e761" class="outline-3">
<h3 id="org615e761">Definizioni</h3>
<div class="outline-text-3" id="text-org615e761">
<p>
Innanzitutto si parte col definire un <b>dominio</b> \(\mathscr{X}\) iniziale di oggetti sui quali noi vogliamo fare predizioni.
Modelliamo ognuno di questi oggetti come un vettore \(x \in \mathbb{R}^d\).
Indichiamo gli elementi del vottore col termine <b>features</b>.
Infine diremo che la <b>dimensionalità</b> del nostro problema è pari al numero di features degli elementi (ovvero \(d\)).<br />
</p>

<p>
Dato che in genere noi vogliamo <i>classificare</i> gli elementi di \(\mathscr{Y}\), indichaimo con \(\mathscr{Y}\) l'insieme delle <i>"etichette"</i> possibili che possiamo assegnare agli elementi di \(\mathscr{X}\).
Più precisamente, quando \(\mathscr{Y}\) è continuo, allora diremo che stiamo trattando un problema di <b>regressione</b>, quando invece \(\mathscr{Y}\) è dicreto, allora diremo che è un problema di <b>classificazione</b>.<br />
</p>

<p>
Un <b>training set</b> \(\mathscr{T} \subseteq \mathscr{X} \times \mathscr{Y}\) è un insieme di <i>coppie ordinte</i> \((x_1, t_1), ..., (x_n, t_n)\), oguna delle quali formata da un item \(x_i \in \mathscr{X}\) e dal suo relativo valore target (effettivo) \(t_i \in \mathscr{Y}\).
Generalmente si indica con \(\mathbf{X} \in \mathbb{R}^{n \times d}\) la matrice degli item \(x_1, ..., x_n\), detta anche <b>feature matrix</b>, e con \(t \in \mathbb{R}^n\) il vettore dei relativi valori target, detto <b>target vector</b>.
</p>
\begin{equation*}
\mathbf{X} = \left (
\begin{array}{ccc}
  x_{11} & x_{12} & \cdots & x_{1d}\\
  x_{21} & x_{22} & \cdots & x_{2d}\\
  \vdots & \vdots & \ddots & \vdots\\
  x_{n1} & x_{n2} & \cdots & x_{nd}
\end{array}
\right ) \in \mathbb{R}^{n \times d}
\end{equation*}

\begin{equation*}
t = \left (
\begin{array}{ccc}
  t_1\\
  t_2\\
  \vdots\\
  t_n
\end{array}
\right ) \in \mathbb{R}^{n}
\end{equation*}
<p>
<br />
Dato un training set \(\mathscr{T}\), un apprenditore automatico \(A\) è un algoritmo che ritorna una <b>regola di predizione</b> (<i>classificatore</i> o <i>regressore</i> in base al dominio) del tipo
\[
   A(\mathscr{T}) = h : \mathscr{X} \to \mathscr{Y}
   \]
<br />
Noi assumiamo che ogni oggeto del training set \(\mathscr{T}\) è campionato dal dominio \(\mathscr{X}\) in accordo a una <b>distribuzione</b> \(\mathscr{D}_1\).
Perciò, per ogni elemento \(x \in \mathscr{X}\) avremo che \(p_{\mathscr{D}_1}(x)\) è la porbabilità che \(x\) sia presente nell'insieme \(\mathscr{T}\).<br />
</p>

<p>
Analogamente assumiamo che anghe i rispettivi valori target degli elementi in \(\mathscr{T}\) sono campionati in accordo a una distribuzione \(\mathscr{D}_2\), <b>condizionata</b> sugli elementi di \(\mathscr{X}\).
Perciò, per ogni \(t \in \mathscr{Y}\) avremo che \(p_{\mathscr{D}_2}(t \vert x)\) è la porbabilità che osservando il valore di target di \(x\) nel training set \(\mathscr{T}\), esso sia pari a \(t\).<br />
</p>

<p>
<b>IMPORTANTE:</b> per il momento trascuriamo questa definizione generale probabilistica, e assumiamo che la relazione tra oggetti e valori di target sia deterministica, ovvero una funzione ben definita \(f\) tale che \(t_i = f(x_i)\).<br />
</p>
</div>
</div>

<div id="outline-container-orgd316290" class="outline-3">
<h3 id="orgd316290">Prediction Risk</h3>
<div class="outline-text-3" id="text-orgd316290">
<p>
Fissiamo un elemetno \(x \in \mathscr{X}\), con un rispettivo valore di target \(y \in \mathscr{Y}\) (nelle nostre assunzioni avremo \(y = f(x)\)).
</p>

<p>
Dato un generico predittore \(h : \mathscr{X} \to \mathscr{Y}\), l'<b>errore</b> rispetto \(x\) si ottiene confrontando la preizione \(h(x)\) e il reale valore target \(y\).
Il rapporto tra i due valori (predizione e target effettivo), è fatta in accordo a una <b>regola</b> che predefiniamo a priori e che dipende dal contesto.
Per esempio, sbagliare a riconoscere il numero 2 o il numero 8 scritti a mano sono errori poco gravi e con uguale gravità.
Viceversa, dare un <i>falso negativo</i> nella diagnosi di un tumore è decisamente molto più grave che dare un <i>flaso positivo</i>.<br />
Tale regola di paragone è nota come <b>Loss Function</b>
\[
   L : \mathscr{Y} \times \mathscr{Y} \to \mathbf{R}
   \]
</p>

<p>
L'<b>errore di predizione</b> di un predittore \(h(x)\) rispetto ad \(x\) è ricavata semplicemente applicando la <i>loss function</i>
\[
   \mathscr{R}(h(x), y) = L(h(x), y)
   \]
<br />
Consideriamo ora il caso in cui il valore target \(y\) non è definito deterministicamente come \(y = f(x)\), ma ripsetta la probabilità condizionata \(p_{\mathscr{D}_2}(y \vert x)\).
Allora in questo caso l'errore di predizione è definito come la <span class="underline">media</span> della loss function al variare di tutti i possibili valori target \(y\) che \(x\) può assumere.
\[
   \mathscr{R}(h(x)) = \mathbb{E}_{\mathscr{D}_2} [ L(h(x), y) ] = \int_{\mathscr{Y}} L(h(x), y) \cdot p_{\mathscr{D}_2}(y \vert x) \, dy
   \]
oppure nel caso di \(\mathscr{Y}\) discreto
\[
   \mathscr{R}(h(x)) = \mathbb{E}_{\mathscr{D}_2} [ L(h(x), y) ] = \sum_{y \in \mathscr{Y}} L(h(x), y) \cdot p_{\mathscr{D}_2}(y \vert x)
   \]
<br />
Alla luce di questo, possiamo dire che predittore \(h^*\) è ottimo se minimizza la sua misura di rischio di predizione.
Nel caso di \(\mathscr{Y}\) avremo
\[
   h^*(x) = arg \min_{h : \mathscr{X} \to \mathscr{Y}} \mathscr{R}(h(x), f(x)) = arg \min_{h : \mathscr{X} \to \mathscr{Y}} L(h(x), f(x))
   \]
oppure nel caso probabilistico
\[
   h^*(x) = arg \min_{h : \mathscr{X} \to \mathscr{Y}} \mathscr{R}(h(x), f(x)) = arg \min_{h : \mathscr{X} \to \mathscr{Y}} \mathbb{E}_{\mathscr{D}_2} [ L(h(x), f(x)) ]
   \]
<br />
Avvolte si necessita di misurare l'errore di un predittore \(h\) in maniera più generale, e non in funzione dei singoli oggetti \(x\) in input.
In questo caso, basta calcolare la <b>media</b> di \(\mathscr{R}\) al varirare di tutte le \(x\) del dominio.<br />
</p>

<p>
Nel caso di \(y\) deterministicamente ricavato da una <i>funzione</i> \(f\) avremo 
\[
   \mathscr{R}(h) = \mathbb{E}_{\mathscr{D}_1,f} [ L(h(x), f(x)) ] = \int_{\mathscr{X}} L(h(x), f(x)) \cdot p_{\mathscr{D}_1}(x) \, dx
   \]
Invece, quando \(y\) dipende dalla distribuzione \(\mathscr{D}_2\) in maniera condizionata dalla scelta di \(x\), possiamo calcolare il rischio come la media di una v.a. <b>multivariabile</b>, ovvero
\[
   \mathscr{R}(h) = \mathbb{E}_{\mathscr{D}_1,\mathscr{D}_2} [ L(h(x), y) ] = \int_{\mathscr{X}}\int_{\mathscr{Y}} L(h(x), y) \cdot p_{\mathscr{D}_2}(f(x) \vert x) \, dy \, dx
   \]
<br />
Il problema principale di queste definizioni è che generalmente non sono noti ne la funzione \(f\) ne la distribuzione  \(\mathscr{D}_2\) di \(p_{\mathscr{D}_2}(y \vert x)\).
Osservando che le uniche informazioni certe di cui siamo in possesso (relative a \(\mathscr{D}_1,\mathscr{D}_2\) o \(f\)) ce le abbiamo rispetto ai dati del training set \(\mathscr{T}\).<br />
</p>

<p>
Perciò empiricamente possiamo impiegare una <b>media aritmetica</b> rispetto alle sole informazioni di \(\mathscr{T}\) per ottenere il cosidetto <b>rischio empirico</b> \(\mathscr{\overline{R}}(h)\).
\[
   \mathscr{\overline{R}}_{\mathscr{T}}(h) = \frac{1}{\vert \mathscr{T} \vert } \sum_{(x_i,t_i) \in \mathscr{T}} L(h(x), t)
   \]
<br />
Concludiamo dicendo che l'approccio del machine learning consiste nel derivare un predittore \(h\) che (quantomeno in maniera approssimata) minimzza il <b>rischio empirico</b> calcolato rispetto alle informazioni contenute nel training set \(\mathscr{T}\).<br />
</p>

<p>
Perciò il problema dell'apprendimento automatico si riduce un problema di minimizzazione in un certo spazio delle funzioni \(\mathscr{H}\), ovvero l'insieme di tutti i possibili predittori \(h\).
\[
   h^* = arg \min_{h \in \mathscr{H}} \mathscr{\overline{R}}_{\mathscr{T}}(h)
   \]
L'insieme di funzioni \(\mathscr{H}\) nel quale effettuiamo la ricerca è anche detto <b>hypothesis set</b> (<b>insieme di ipotesi</b>) o <b>inductive bias</b>.
</p>
<hr />
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="date">Data: 2022-03-15 mar 00:00</p>
<p class="author">Autore: Alessandro Straziota</p>
<p class="email">Email: <a href="mailto:alessandrostr95@gmail.com">alessandrostr95@gmail.com</a></p>
<p class="date">Created: 2022-03-18 ven 13:03</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
