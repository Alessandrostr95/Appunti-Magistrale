<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it">
<head>
<!-- 2021-12-28 mar 18:26 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>AR - Lesson 12</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Alessandro Straziota" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" href="/appunti.css" />
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2020 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="h" href=""> UP </a>
 |
 <a accesskey="H" href="/"> HOME </a>
</div><div id="content">
<h1 class="title">AR - Lesson 12</h1>
<div id="table-of-contents">
<h2>Indice</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orge2a7bf3">Herding - Seguire il Gregge</a>
<ul>
<li><a href="#orga14b25b">A Simple Herding Experiment: Il Gioco delle Urne</a></li>
<li><a href="#orge9ba485">Teorema di Bayes</a></li>
<li><a href="#org5d2bba0">Un Modello Generale di Sequential Decision Making</a>
<ul>
<li><a href="#orga81b859">Punto 1: Decisioni Individuali</a></li>
<li><a href="#orge12af70">Punto 2: Informazioni Private</a></li>
<li><a href="#orgabe3c44">Punto 3: Osservazioni</a></li>
<li><a href="#orgb79a27b">Punto 4: Decisioni Sequenzali</a></li>
<li><a href="#orgecaf3fd">Punto 5: Decisioni Razionali</a></li>
<li><a href="#orgcfd0a0b">Punto 6: Massa Critica</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>


<div id="outline-container-orge2a7bf3" class="outline-2">
<h2 id="orge2a7bf3">Herding - Seguire il Gregge</h2>
<div class="outline-text-2" id="text-orge2a7bf3">
<p>
Abbiamo visto che quando degli individui sono connessi tra di loro in una <i>rete</i>, le loro decisioni e comportamenti possono essere influenzati (ed influenzare) da quello degli altri individui vicini.<br />
</p>

<p>
Nello studio dei <a href="./09.html">processi di diffusione</a> abbiamo visto come il comportamento dei singoli individui veniva influenzato dalla <i>diretta comunicazione</i> col proprio viciano.
In questa sezione vedremo come le decisioni dei singoli individui possono essere influenzate dalle osservazioni fatte sul comportamento degli altri, senza lo scambio di alcuna informaione.
In sostanza come è possibile <i>estrapolare informazioni</i> dal comportamento della massa.<br />
</p>

<p>
Come primo esempio supponiamo di essere in vacanza in un nuovo posto e di dover scegliere un ristorante in cui mangiare.
In base alle nostre recerche <span class="underline">personali</span> scopriamo che il ristorante <code>A</code> è il migliore che ci sia in zona, e quindi decidiamo di andarci.
Poco prima di entrare vediamo che nel ristorante accanto, il ristorante <code>B</code>, c'è moltissima clientela, mentre il ristorante <code>A</code> è praticamente vuoto.
Non è del tutto irrazionale pensare che tutte le persone che vanno al ristorante <code>B</code> abbiano <b>informazioni private</b> che noi non abbiamo, e supporre che in realtà il ristorante è il migliore.
In effetti il fatto che il ristorante <code>A</code> sia quasi vuoto non aiuta: verrebbe da pensare che siamo in possesso di informazioni non del tutto esatte o complete.
Perciò decidiamo anche noi di andare al ristorante <code>B</code>.<br />
</p>

<p>
In questo caso diremo che è avvenuta una <b>cascata informativa</b> (o <b>herding</b>).
In poche parole, una cascata informativa occorre quando gli individui prendono decisioni in maniera sequenziale, osservando ciò che hanno fatto gli altri prima e cercando di inferire qualche informazione aggiuntiva che ha spinto gli altri ad agire in tale maniera.<br />
</p>

<p>
La cosa più interessante è che gli individui che <i>"imitano"</i> gli altri non lo fanno del tutto stupida, bensì facendo una serie di ragionamenti ed inferenze più che sensate.
Naturalmente, l'imitazione può verificarsi anche a causa della pressione sociale all'esigienza di volersi conformare, senza alcuna causa informativa sottostante, e non è sempre facile distinguere questi due fenomeni.
Consideriamo infatti l'esperimento di <i>Milgram</i>, <i>Bickman</i> e <i>Berkowitz</i> del 1960, in cui venivano poste agli angoli delle strade dei gruppi di persone (da un minimo di 1 a un massimo di 15) a guardare il cielo senza alcun motivo.
Si è osservato quanti passanti si sono fermati e hanno volto lo sguardo al cielo.
Come prima osservazione si è visto che con una sola persona, pochissimi passanti si fermavano.
Se invece 5 persone fissavano il cielo, alcuni passanti si fermavanom a imitare, ma la maggior parte li ignorava.
Infine, con un gruppo di 15 persone che guardano verso l'alto, hanno scoperto che il 45% dei passanti imitava, fermandosi e guardare il cielo cercando di capire.<br />
</p>

<p>
Quest'ultimo esperimento lascia pensare che esiste una <b>soglia critica</b> oltre la quale si scatena l'<i>herding</i> su una considerevole porzione di popolazione.
Infatti, se camminando per strada vediamo due persone che fissano il cielo, è naturale pensare che i due individui non siano proprio sani mentalmente.
Se invece ne vediamo 15, molto propbabilmente guarderemo anche noi verso l'alto, per cercare di capire cosa c'è di interessante.<br />
</p>

<p>
Alcune domande nascono spontanee:
</p>
<ul class="org-ul">
<li>esiste sempre una soglia critica che scatena l'herding di massa?</li>
<li>e se esiste, come fare a trovarla?</li>
</ul>
</div>

<div id="outline-container-orga14b25b" class="outline-3">
<h3 id="orga14b25b">A Simple Herding Experiment: Il Gioco delle Urne</h3>
<div class="outline-text-3" id="text-orga14b25b">
<p>
Consideriamo un genere di gioco con la seguente tipologia di regole
</p>

<ol class="org-ol">
<li>C'è una decisione da prendere</li>
<li>I giocatori prendono le proprie decisioni in sequenza (uno dopo l'altro), e ogni persona può osservare le scelte fatte da coloro che hanno agito prima.</li>
<li>Ogni giocatore ha alcune <i>informazioni private</i> che aiutano a guidare la propria decisione.</li>
<li>Un giocatore non può osservare direttamente le informazioni private che gli altri giocatori hanno, ma può trarre deduzioni su queste informazioni private da ciò che fanno.</li>
</ol>

<p>
Secondo queste indicazioni, instanziamo un gioco con le seguenti regole:
</p>
<ul class="org-ul">
<li>C'è uno <b>scommettitore</b> in una stanza chiusa, e una serie di <b>giocatori</b> all'esterno.</li>
<li>Lo scommettitore inserisce due palline rosse ed una blu in un'urna (che chiameremo <code>MR</code>, a <i>Maggioranza Rossa</i>), e due palline blu e una rossa in un'altra urna (che chiameremo <code>MB</code>, a <i>Maggioranza Blu</i>).</li>
<li>Lo scommettitore poi mischia le due urne e ne sceglie una a caso (senza avere la possibilità di vederne il contenuto).</li>
<li>Un giocatore alla volta entra nella stanza ed estrae una pallina dall'urna, e poi la reinserisce.</li>
<li>Il giocatore comunica a tutti quanti se ritiene che l'urna sia <code>MR</code> o <code>MB</code> (sulla base delle sue informazioni).
<b>Importante:</b> il giocatore non deve comunicare il colore della pallina pescata.</li>
<li>Al termine vinceranno solo i giocatori che hanno indovinato quale urna è stata scelta inizialmente (<code>MR</code> o <code>MB</code>).</li>
</ul>

<p>
Per definizione di questo gioco, l'informazione privata dei singoli giocatori è l'esito dell'estrazione (pallina blu o pallina rossa), e questa non viene mai condivisa con gli altri.
Un giocatore però può inferire quale urna è meglio scegliere in base alle scelte fatte dagli altri prima (come vedremo adesso).<br />
</p>

<dl class="org-dl">
<dt>Primo giocatore</dt><dd>prima di estrarre la pallina, il primo giocatore è in possesso della sola informazione <i>"l'urna è <code>MR</code> o <code>MB</code>"</i>.
Non avnedo altre informazioni, a prescindere da cosa pescherà il primo giocatore, la probabilità che l'urna sia <code>MR</code> o <code>MB</code> è la stessa.
Perciò gli conviene scomettere sul colore della pallina estratta: se pesca una pallina blu gli conviene scommettere su <code>MB</code> (stesso discorso per <code>MR</code>).</dd>
<dt>Secondo giocatore</dt><dd>a questo punto il secondo giocatore può dedurre l'esito dell'estrazione del primo giocatore sulla base della sua scommessa.
Senza perdita di generalità, supponiamo che il primo giocatore abbia scommesso <code>MB</code> (e che quindi abbia estratto una pallina blu).
Se il secondo estrae una pallina blu, allora sa che sono state esatratte due palline blu consecutive, e che quindi è più conveniente scommettere su <code>MB</code>.
Se invece estrae una pallina rossa, si ritrova nella stessa situazione inizale del primo giocatore (senza alcuna informazione rilevante), perciò gli conviene scommettere <code>MR</code> in accordo alla sua estrazione.</dd>
<dt>Terzo giocatore</dt><dd>anche il terzo giocatore è in grado di dedurre le estrazioni dei giocatori precedenti: se sono discordi allora sono avvenute due estrazioni discorde, se sono concorde allora sono avvenute due estrazioni di palline dello stesso colore.
Consideriamo il caso in cui le prime due estrazioni siano discordi, in questo caso al terzo giocatore conviene rispondere in accordo a ciò che pesca (se pesca una pallina blu gli conviene votare <code>MB</code>, se ne pesca una rossa gli conviene votare <code>MR</code>).
Consideriamo ora il caso in cui i primi due giocatori abbiamo voti condori, e senza perdita di generalità supponiamo che abbiano entrambi votato <code>MB</code>.
Se il terzo giocatore pesca una pallina blu, allora vuol dire che sono state estratte tre palline blu di seguito, rafforzando la propbailità che <code>MB</code> sia la risposta esatta.
Se invece estrae una rossa, comunque è più probabile che la risposta esatta sia <code>MB</code>, perché sono state estratte due palline blu di seguito e poi una rossa.
Quindi in ogni caso gli conviene votare <code>MB</code>.</dd>
<dt>Quarto giocatore</dt><dd>a questo punto il quarto giocatore può dedurre ciò che hanno fatto <span class="underline">tutti</span> i giocatori precedenti solamente se ci sono 2 voti concordi ed uno discorde (2 a 1).
Perché se ci fossero 3 voti concordi, sappiamo che il terzo giocatore avrebbe votato in accordo ai primi due in ogni caso a prescindere dall'esito della sua estrazione.
Supponiamo di essere nella situazione di <i>"3 a 0"</i> per <code>MB</code>.
Al quarto giocatore conviene votare <code>MB</code> in ogni caso (esattamente come per il terzo giocatore).</dd>
</dl>

<p>
A questo punto, dal quinto giocatore in poi, si genera una <i>cascata informativa</i> a favore di <code>MB</code>, a prescindere dalle singole estrazioni.
</p>
</div>
</div>

<div id="outline-container-orge9ba485" class="outline-3">
<h3 id="orge9ba485">Teorema di Bayes</h3>
<div class="outline-text-3" id="text-orge9ba485">
<p>
Per formalizzare meglio la meccanica precedentemente descritta è necessario enunciare il <b>Teorema di Bayes</b>.<br />
</p>

<blockquote>
<p>
<b>Teorema di Bayes</b>
siano i due eventi \(A,B \in \Omega\) di probabilità <span class="underline">non nulla</span>, allora
\[
   \mathcal{P}(A | B) = \frac{\mathcal{P}(B | A) \cdot \mathcal{P}(A)}{ \mathcal{P}(B) }
   \]
</p>
</blockquote>

<blockquote>
<p>
<b>Proof</b>
per definizione di probabilità condizionata abbiamo che
</p>
\begin{align*}
  \mathcal{P}(A | B) &= \frac{\mathcal{P}(A \cap B)}{\mathcal{P}(B)}\\
  \mathcal{P}(B | A) &= \frac{\mathcal{P}(A \cap B)}{\mathcal{P}(A)}
\end{align*}
<p>
ciò implica che
\[
   \mathcal{P}(A \cap B) = \mathcal{P}(A | B) \cdot \mathcal{P}(B) = \mathcal{P}(B | A) \cdot \mathcal{P}(A)
   \]
Sostituendo opportunamente otteniamo l'enunciato del teorema
\[
   \mathcal{P}(A | B) = \frac{\mathcal{P}(A \cap B)}{\mathcal{P}(B)} = \frac{\mathcal{P}(B | A) \cdot \mathcal{P}(A)}{\mathcal{P}(B)} \;\; \square
   \]
</p>
</blockquote>

<p>
Facendo qualche opportuna sostituzione, possiamo riscrivere \(\mathcal{P}(B)\) come segue
</p>
\begin{align*}
  \mathcal{P}(B) &= \mathcal{P}(B \cap \Omega)\\
  &= \mathcal{P}(B \cap (A \cup A^{\mathcal{C}}))\\
  &= \mathcal{P}((B \cap A) \cup (B \cap A^{\mathcal{C}}))\\
  &= \mathcal{P}(B \cap A) + \mathcal{P}(B \cap A^{\mathcal{C}})\\
  &= \mathcal{P}(B | A) \cdot \mathcal{P}(A) + \mathcal{P}(B | A^{\mathcal{C}}) \cdot \mathcal{P}(A^{\mathcal{C}})
\end{align*}   
<p>
perciò
\[
   \mathcal{P}(A | B) = \frac{\mathcal{P}(B | A) \cdot \mathcal{P}(A)}{ \mathcal{P}(B | A) \cdot \mathcal{P}(A) + \mathcal{P}(B | A^{\mathcal{C}}) \cdot \mathcal{P}(A^{\mathcal{C}}) }
   \]
</p>

<p>
Siano gli eventi:
</p>
<ul class="org-ul">
<li>\(MR\) : <i>"l'urna è a maggioranza rossa"</i></li>
<li>\(MB\) : <i>"l'urna è a maggioranza blu"</i></li>
<li>\(r\) : <i>"è stata estratta una pallina rossa"</i></li>
<li>\(b\) : <i>"è stata estratta una pallina blu"</i></li>
</ul>

<p>
Osserviamo inoltre che i precedenti eventi sono mutualmente complementari
\[
   MR = MB^{\mathcal{C}}\\
   MB = MA^{\mathcal{C}}\\
   b = r^{\mathcal{C}}\\
   r = b^{\mathcal{C}}
   \]
</p>

<p>
Secondo le regole del gioco sappiamo che
\[
   \mathcal{P}(MR) = \mathcal{P}(MB) = \frac{1}{2}\\
   \mathcal{P}(r | MR) = \frac{2}{3}; \;\; \mathcal{P}(b | MR) = \frac{1}{3}\\
   \mathcal{P}(r | MB) = \frac{1}{3}; \;\; \mathcal{P}(b | MB) = \frac{2}{3}
   \]
</p>

<p>
<b>Giocatore 1:</b> Supponiamo senza perdita di generalità che il primo giocatore estrae una pallina blu, essi dovrà calcolare la probabilità che l'urna sia a maggioranza blu o rossa,
e questo si può fare grazie al teorema di Bayes
</p>
\begin{align*}
  \mathcal{P}(MB | b) &= \frac{\mathcal{P}(b | MB) \cdot \mathcal{P}(MB)}{\mathcal{P}(b | MB) \cdot \mathcal{P}(MB) + \mathcal{P}(b | MR) \cdot \mathcal{P}(MR)} = \frac{2}{3}\\
  \\
  \mathcal{P}(MR | b) &= \frac{\mathcal{P}(b | MR) \cdot \mathcal{P}(MR)}{\mathcal{P}(b | MR) \cdot \mathcal{P}(MR) + \mathcal{P}(b | MB) \cdot \mathcal{P}(MB)} = \frac{1}{3}
\end{align*}
<p>
perciò al primo giocatore conviene votare in accordo alla sua estrazione.<br />
</p>

<p>
<b>Giocatore 2:</b> Vediamo ora quale strategia è migliore per il secondo giocatore.
Consideriamo come prima situazione quella in cui esso estrae una pallina rossa, ed indichiamo con \(br\) l'evento <i>"sono state estratte in ordine una pallina blu e poi una rossa"</i>.
Dato che il secondo giocatore sa esasttamente cosa ha pescato il primo (dato che lo può inferire con certezza assumendo che il primo giocaotre giochi correttamente),
si può affermare che il secondo giocatore si trova a dover calcolare le seguenti probabilità
</p>
\begin{align*}
  \mathcal{P}(MB | br) &= \frac{\mathcal{P}(br | MB) \cdot \mathcal{P}(MB)}{\mathcal{P}(br | MB) \cdot \mathcal{P}(MB) + \mathcal{P}(br | MR) \cdot \mathcal{P}(MR)} = \frac{1}{2}\\
  \\
  \mathcal{P}(MR | br) &= \frac{\mathcal{P}(br | MR) \cdot \mathcal{P}(MR)}{\mathcal{P}(br | MR) \cdot \mathcal{P}(MR) + \mathcal{P}(br | MB) \cdot \mathcal{P}(MB)} = \frac{1}{2}
\end{align*}
<p>
perciò il secondo giocatore non può estrarre alcuna informazione utile dall'estrazione del primo, e quindi gli conviene scommettere in accordo a ciò che estrae.<br />
</p>

<p>
Consideriamo ora il caso in cui il secondo giocate estrae una pallina blu.
In questo l'informazione riguardo la prima estrazione è realmente utile, in quanto possiamo dire che la probabilità è nettamente più sbilanciata verso <code>MB</code>
</p>
\begin{align*}
  \mathcal{P}(MB | bb) &= \frac{\mathcal{P}(bb | MB) \cdot \mathcal{P}(MB)}{\mathcal{P}(bb | MB) \cdot \mathcal{P}(MB) + \mathcal{P}(bb | MR) \cdot \mathcal{P}(MR)} = \frac{4}{5}\\
  \\
  \mathcal{P}(MR | bb) &= \frac{\mathcal{P}(bb | MR) \cdot \mathcal{P}(MR)}{\mathcal{P}(bb | MR) \cdot \mathcal{P}(MR) + \mathcal{P}(bb | MB) \cdot \mathcal{P}(MB)} = \frac{1}{5}
\end{align*}

<p>
<b>Giocatore 3:</b> A questo punto (sempre supponendo che la prima estrazione sia stata una pallina blu) possiamo essere in due situazioni differenti
</p>
<ul class="org-ul">
<li>\(br\): sono avvenute in sequenza le estrazioni <i>blu-rossa</i></li>
<li>\(bb\): sono avvenute in sequenza le estrazioni <i>blu-blu</i></li>
</ul>

<p>
Partendo dalla prima, vediamo quale è la strategia migliore per il terzo giocatore.<br />
</p>

<p>
<b>Caso \(brb\):</b>
</p>
\begin{align*}
  \mathcal{P}(MB | brb) &= \frac{\mathcal{P}(brb | MB) \cdot \mathcal{P}(MB)}{\mathcal{P}(brb | MB) \cdot \mathcal{P}(MB) + \mathcal{P}(brb | MR) \cdot \mathcal{P}(MR)} = \frac{2}{3}\\
  \\
  \mathcal{P}(MR | brb) &= \frac{\mathcal{P}(brb | MR) \cdot \mathcal{P}(MR)}{\mathcal{P}(brb | MR) \cdot \mathcal{P}(MR) + \mathcal{P}(brb | MB) \cdot \mathcal{P}(MB)} = \frac{1}{3}
\end{align*}

<p>
<b>Caso \(brr\):</b>
</p>
\begin{align*}
  \mathcal{P}(MB | brr) &= \frac{\mathcal{P}(brr | MB) \cdot \mathcal{P}(MB)}{\mathcal{P}(brr | MB) \cdot \mathcal{P}(MB) + \mathcal{P}(brr | MR) \cdot \mathcal{P}(MR)} = \frac{1}{3}\\
  \\
  \mathcal{P}(MR | brr) &= \frac{\mathcal{P}(brr | MR) \cdot \mathcal{P}(MR)}{\mathcal{P}(brr | MR) \cdot \mathcal{P}(MR) + \mathcal{P}(brr | MB) \cdot \mathcal{P}(MB)} = \frac{2}{3}
\end{align*}

<p>
Perciò se i pirmi due voti sono discordi al terzo giocatore conviene votare in accordo alla sua estrazione (come già intuito in precedenza).
Vediamo ora cosa accade se i primi due giocatori hanno voti concordi.<br />
</p>

<p>
<b>Caso \(bbb\):</b>
</p>
\begin{align*}
  \mathcal{P}(MB | bbb) &= \frac{\mathcal{P}(bbb | MB) \cdot \mathcal{P}(MB)}{\mathcal{P}(bbb | MB) \cdot \mathcal{P}(MB) + \mathcal{P}(bbb | MR) \cdot \mathcal{P}(MR)} = \frac{8}{9}\\
  \\
  \mathcal{P}(MR | bbb) &= \frac{\mathcal{P}(bbb | MR) \cdot \mathcal{P}(MR)}{\mathcal{P}(bbb | MR) \cdot \mathcal{P}(MR) + \mathcal{P}(bbb | MB) \cdot \mathcal{P}(MB)} = \frac{1}{9}
\end{align*}

<p>
<b>Caso \(bbr\):</b>
</p>
\begin{align*}
  \mathcal{P}(MB | bbr) &= \frac{\mathcal{P}(bbr | MB) \cdot \mathcal{P}(MB)}{\mathcal{P}(bbr | MB) \cdot \mathcal{P}(MB) + \mathcal{P}(bbr | MR) \cdot \mathcal{P}(MR)} = \frac{2}{3}\\
  \\
  \mathcal{P}(MR | bbr) &= \frac{\mathcal{P}(bbr | MR) \cdot \mathcal{P}(MR)}{\mathcal{P}(bbr | MR) \cdot \mathcal{P}(MR) + \mathcal{P}(bbr | MB) \cdot \mathcal{P}(MB)} = \frac{1}{3}
\end{align*}

<p>
In questo caso al giocatore 3 conviene votare in accordo a ciò che hanno votato i primi due giocatori, a prescindere da quale sarà l'esito della sua estrazione.<br />
</p>

<p>
<b>Giocatore 4:</b> Senza perdita di generalità consideriamo il caso in cui le prime due estrazioni sono entrambe <i>blu</i>.
Il giocatore 4 non può essere certo di cosa ha estratto il giocatore 3, perciò gli conviene sempre calcolare due probabilità differenti, quella in cui il terzo ha estratto una pallina <i>rossa</i> e quella in cui ne ha estratta una <i>blu</i>.
</p>
\begin{align*}
  \mathcal{P}(MB | bbbb) = \frac{16}{17}; \;\; &\mathcal{P}(MR | bbbb) = \frac{1}{17}\\
  \mathcal{P}(MB | bbbr) = \frac{8}{9}; \;\; &\mathcal{P}(MR | bbbr) = \frac{1}{9}\\
  \mathcal{P}(MB | bbrb) = \frac{8}{9}; \;\; &\mathcal{P}(MR | bbrb) = \frac{1}{9}\\
  \mathcal{P}(MB | bbrr) = \frac{1}{2}; \;\; &\mathcal{P}(MR | bbrr) = \frac{1}{2}
\end{align*}

<p>
Perciò votando <code>MB</code> il giocatore 4 non ricade mai nella strategia che minimizza la probabilità di sucesso.
Al più può ritrovarsi nel caso in cui le probabilità di successo e insuccesso equivalgono, ovvero quando giocatori 3 e 4 estraggono entrambi una pallina <i>rossa</i>.
Putroppo però il giocatore 4 non può sapere cosa ha estratto il terzo giocatore, perciò gli conviene votare comunque <code>MB</code> a prescindere dalla sua estrazione.<br />
</p>

<p>
<b>Giocatore 5:</b> sapendo che le prime due estrazioni sono state <i>blu-blu</i>, il giocatore 5 (come il giocatore 4) deve calcolare tutte le probabilità rispetto alle possibili 
combinazioni di estrazioni dei giocatori 3 e 4.<br />
</p>

<p>
<b>Caso \(bbbb\):</b>
</p>
\begin{align*}
  \mathcal{P}(MB | bbbbb) = \frac{32}{33}; \;\; &\mathcal{P}(MR | bbbbb) = \frac{1}{33}\\
  \mathcal{P}(MB | bbbbr) = \frac{8}{9}; \;\; &\mathcal{P}(MR | bbbbr) = \frac{1}{9}
\end{align*}

<p>
<b>Caso \(bbbr\):</b>
</p>
\begin{align*}
  \mathcal{P}(MB | bbbrb) = \frac{8}{9}; \;\; &\mathcal{P}(MR | bbbrb) = \frac{1}{9}\\
  \mathcal{P}(MB | bbbrr) = \frac{2}{3}; \;\; &\mathcal{P}(MR | bbbrr) = \frac{1}{3}
\end{align*}

<p>
<b>Caso \(bbrb\):</b>
</p>
\begin{align*}
  \mathcal{P}(MB | bbrbb) = \frac{8}{9}; \;\; &\mathcal{P}(MR | bbrbb) = \frac{1}{9}\\
  \mathcal{P}(MB | bbrbr) = \frac{2}{3}; \;\; &\mathcal{P}(MR | bbrbr) = \frac{1}{3}
\end{align*}

<p>
<b>Caso \(bbrr\):</b>
</p>
\begin{align*}
  \mathcal{P}(MB | bbrrb) = \frac{2}{3}; \;\; &\mathcal{P}(MR | bbrrb) = \frac{1}{3}\\
  \bigstar \mathcal{P}(MB | bbrrr) = \frac{1}{3}; \;\; &\mathcal{P}(MR | bbrrr) = \frac{2}{3}
\end{align*}

<p>
Al giocatore 5 conviene sempre scommettere su <code>MB</code> a meno che il terzo e il quarto giocatore non abbiano estratto due palline <i>rosse</i>.
Questo purtroppo il giocatore 5 non può saperlo, in quanto i giocatori 3 e 4 voteranno <code>MB</code> a prescindere dall'esito delle proprie estrazioni.<br />
</p>

<p>
Perciò possiamo dire che se le prime due estrazioni sono <i>blu-blu</i> si genera una cascata imitativa in cui tutti i giocatori voteranno <code>MB</code>,
a prescindere dalle proprie informazioni private!<br />
</p>
</div>
</div>

<div id="outline-container-org5d2bba0" class="outline-3">
<h3 id="org5d2bba0">Un Modello Generale di Sequential Decision Making</h3>
<div class="outline-text-3" id="text-org5d2bba0">
<p>
Come visto negli esperimenti precedenti o nel gioco delle due urne, il fenomeno dell'<i>Herding</i> si presenta in situazioni che hanno delle caratteristiche in comune, ovvero:
</p>
<ol class="org-ol">
<li>Ogni individuo deve prendere una decisione.</li>
<li>Ogni individuo ha una propria informazione <b>privata</b>.</li>
<li>Ogni individuo riceve dalla rete un'informazione incompleta, ovvero sa le scelte degli altri individui ma non l'informazione che li ha spinti a prendere tali decisioni.</li>
<li>Le decisioni vengono prese in sequenza, dopo aver osservato quello che hanno fatto gli altri in precedenza.</li>
<li>Ogni individuo prende la propria decisione in maniera <b>puramente razionale</b>: inferisce dalle proprie osservazioni quale è la strategia migliore da adottare, senza alcuna influenza o pressione sociale.</li>
<li>Si scatena una <b>cascata informativa</b> (<b>herding</b>), quando una certa <b>massa critica</b> prende una medesima decisione.</li>
</ol>

<p>
Descriviamo ora in maniera formale un modello che cattura tutte queste caratteristiche
</p>
</div>

<div id="outline-container-orga81b859" class="outline-4">
<h4 id="orga81b859">Punto 1: Decisioni Individuali</h4>
<div class="outline-text-4" id="text-orga81b859">
<p>
Per semplicità assumiamo che le decisioni da prendere sono <b>decisioni binarie</b>.
Senza perdita di generalità assumiamo che le uniche due alternative sono
</p>
<ul class="org-ul">
<li><code>Y</code>: l'individuo <i>accetta</i> una proposta.</li>
<li><code>N</code>: l'individuo <i>rifiuta</i> una proposta.</li>
</ul>

<p>
Solo una delle due alternative è quella giusta.
La probabilità che <code>Y</code> sia l'alternativa giusta è \(\mathcal{P}(Y) = p\), mentre la probabilità che quella giusta sia <code>N</code> è \(\mathcal{P}(N) = 1-p\).<br />
</p>

<p>
Se un individuo <b>accetta</b> (<code>Y</code>) una proposta avrà un <i>profitto</i> \(v_g > 0\)<sup><a id="fnr.1" class="footref" href="#fn.1">1</a></sup> se <code>Y</code> era la risposta corretta, o una <i>perdita</i> \(v_b \leq 0\)<sup><a id="fnr.1.100" class="footref" href="#fn.1">1</a></sup> se la risposta <code>Y</code> era errata.
Contrariamente, se l'individuo <b>non accetta</b> (<code>N</code>) non otterrà nessun profitto e nessuna perdita.<br />
</p>

<p>
Affinché sia <i>equivalente</i> per undividuo accettare (<code>Y</code>) o rifiutare (<code>N</code>), deve essere che
\[
    v_g p + v_b(1-p) = 0
    \]
</p>
</div>
</div>

<div id="outline-container-orge12af70" class="outline-4">
<h4 id="orge12af70">Punto 2: Informazioni Private</h4>
<div class="outline-text-4" id="text-orge12af70">
<p>
Ongi individuo possiede un'<b>informazione privata</b>, che possiamo assumere ricevere sottoforma di <b>segnale privato</b>.
I due possibili segnali possono essere <code>A</code> (<code>Accetta</code>) ed <code>R</code> (<code>Rifiuta</code>).<br />
</p>

<p>
Se la scelta giusta è <code>Y</code>, allora la probabilità di ricevere come segnale privato <code>A</code> è \(q > \frac{1}{2}\).
Viceversa se la scelta giusta è <code>N</code>, allora la probabilità di ricevere come segnale privato <code>A</code> è \(1 - q\).
Simmetricamente per <code>R</code>.
Più formalmente possiamo esprimere queste proprietà con probabilità condizionate
</p>
\begin{align*}
  \mathcal{P}(A | Y) = q \;\; &\mathcal{P}(A | N) = 1 - q\\
  \\
  \mathcal{P}(R | Y) = 1 - q \;\; &\mathcal{P}(R | N) = q
\end{align*}
</div>
</div>

<div id="outline-container-orgabe3c44" class="outline-4">
<h4 id="orgabe3c44">Punto 3: Osservazioni</h4>
<div class="outline-text-4" id="text-orgabe3c44">
<p>
L'individuo \(i\)-esimo che deve prendere una decisione ricava dalla rete la sequenza \( (X_1, ..., X_{i-1}) \in \lbrace Y, N \rbrace^{i-1} \)
delle decisioni prese dai precedenti \(i-1\) individui.
</p>
</div>
</div>

<div id="outline-container-orgb79a27b" class="outline-4">
<h4 id="orgb79a27b">Punto 4: Decisioni Sequenzali</h4>
<div class="outline-text-4" id="text-orgb79a27b">
<p>
L'individuo \(i\)-esimo prende una decisione dopo che i precedenti \(i-1\) individui hanno preso la loro.
</p>
</div>
</div>

<div id="outline-container-orgecaf3fd" class="outline-4">
<h4 id="orgecaf3fd">Punto 5: Decisioni Razionali</h4>
<div class="outline-text-4" id="text-orgecaf3fd">
<p>
Supponiamo che per l'individui \(i\) inizialmente <code>Y</code> ed <code>N</code> sono alternative equivalenti, ovvero che \(v_g p + v_b(1-p) = 0\).
Se dopo le decisioni dei primi \(i - 1\) individui la probabilità che <code>Y</code> sia corretta diventa una certa quantità \(p'\),
all'individui \(i\) converrà accettare se e soltanto se 
\[
    v_gp' + v_b(1 - p') \geq 0 
    \]
e questo accade se \(p' \geq p\), ovvero se non peggiora la probabilità che accettare sia la strategia corretta.
</p>
</div>
</div>
<div id="outline-container-orgcfd0a0b" class="outline-4">
<h4 id="orgcfd0a0b">Punto 6: Massa Critica</h4>
<div class="outline-text-4" id="text-orgcfd0a0b">
<p>
Cerchiamo ora di individuare quanto deve essere grande una massa critica che scatena l'<i>herding</i>.<br />
</p>

<p>
Indichiamo con \(S \in \lbrace A, R \rbrace^*\) la sequenza dei <i>segnali privati</i> ricevuti dagli individui.
Consideriamo la scelta del primo individuo, ovvero quando \(\vert S \vert = 1\).
Se \(S = (A)\), allora la probabilità che la scelta corretta sia <code>Y</code> è
</p>
\begin{align*}
  \mathcal{P}(Y \vert A)
  &= \frac{ \mathcal{P}(A \vert Y) \cdot \mathcal{P}(Y) }{ \mathcal{P}(A \vert Y) \cdot \mathcal{P}(Y) + \mathcal{P}(A \vert N) \cdot \mathcal{P}(N)}\\
  &= \frac{qp}{qp + (1-q)(1-p)}\\
(\bigstar q > 1/2) &> \frac{qp}{qp + q(1-p)} = \frac{qp}{qp + q - qp} = p
\end{align*}
<p>
viceversa la probabilità che la scelta corretta sia <code>N</code> ricevendo il segnale <code>A</code> è
\[
    \mathcal{P}(N \vert A) = 1 - \mathcal{P}(Y \vert A) < p 
    \]
</p>

<p>
In maniera simmetrica, se riceviamo come primo segnale privato <code>R</code> avremo che
\[
    \mathcal{P}(Y \vert R) < p\\
    \mathcal{P}(N \vert R) > p
    \]
</p>

<p>
Segue quindi che in assenza di ulteriori informazioni, quando un individuo ha solamente la propria informazione privata, conviene rispondere in accordo ad essa:
se riceve <code>A</code> conviene rispondere <code>Y</code>, se riceve <code>R</code> conviene rispondere <code>N</code>.<br />
</p>

<p>
Consideriamo ora il caso in cui \(\vert S \vert > 1\).
Supponiamo che in qualche maniera l'individuo che deve fare la scelta sia riuscito ad inferire tutta la sequanza di \(S\) (come in alcuni casi del gioco delle due urne).
Diciamo che nella sequenza \(S\) è presente \(a\) volte l'elemento <code>A</code> ed \(r\) volte l'elemento <code>R</code>.
Perciò la probabilità <code>Y</code> sia la risposta esatta, sapendo la sequenza \(S\) di segnali privati sarà
</p>
\begin{align*}
  \mathcal{P}(Y \vert S)
  &= \frac{ \mathcal{P}(S \vert Y) \cdot \mathcal{P}(Y) }{ \mathcal{P}(S \vert Y) \cdot \mathcal{P}(Y) + \mathcal{P}(S \vert N) \cdot \mathcal{P}(N)}\\
  &= \frac{q^a (1-q)^r p}{q^a (1-q)^r p + (1-q)^a q^r (1-p)}
\end{align*}    

<p>
Se \(a > r\), e dato che \(q > 1/2\), avremo al <span class="underline">secondo addendo al denominatore</span> che
\[
    (1-q)^a q^r = (1-q)^{a-r+r} q^r < q^{a-r} (1-q)^r q^r = q^a (1-q)^r
    \]
e quindi
</p>
\begin{align*}
  \mathcal{P}(Y \vert S)
  &= \frac{q^a (1-q)^r p}{q^a (1-q)^r p + (1-q)^a q^r (1-p)}\\
  &> \frac{q^a (1-q)^r p}{q^a (1-q)^r p + q^a (1-q)^r (1-p)} = p
\end{align*}

<p>
Viceversa, se \(a < r\), accade che
\[
    (1-q)^a q^r = (1-q)^a q^a q^{r-a} > (1-q)^a q^a (1-q)^{r-a} = q^a (1-q)^r
    \]
e quindi
</p>
\begin{align*}
  \mathcal{P}(Y \vert S)
  &= \frac{q^a (1-q)^r p}{q^a (1-q)^r p + (1-q)^a q^r (1-p)}\\
  &< \frac{q^a (1-q)^r p}{q^a (1-q)^r p + q^a (1-q)^r (1-p)} = p
\end{align*}

<p>
Infine, se \(a = r\) allora \(q^a (1-q)^r = (1-q)^a q^r\), e quindi \(\mathcal{P}(Y \vert S) = p\).<br />
</p>

<p>
Ricapitolando
\[
    \mathcal{P}(Y \vert S) = \begin{cases}
      > p &\mbox{se } a > r\\
      < p &\mbox{se } a < r\\
      = p &\mbox{se } a = r
    \end{cases}
    \]
Perciò se un individuo conosce l'intera sequenza di segnali privati dei giocatori precedenti, riesce a prendere la scelta che massimizza
la probabilità di vincita in base alla maggioranza:
se ci sono stati più segnali <code>A</code> conviene votare <code>Y</code>, se ce ne sono stati più <code>R</code> conviene votare <code>N</code>.<br />
</p>

<p>
Osservare che il caso in cui \(a = r\) equivale sostanzialmente al caso in cui non si ha alcuna informazione aggiuntiva riguardo la
decisione da prendere (\(\mathcal{P}(Y \vert S) = \mathcal{P}(Y)\)), e quindi bisogna rifarsi solamente al proprio segnale privato.<br />
</p>

<p>
Senza perdita di generalità supponiamo che l'\(n\)-esimo individuo riesca ad inferire tutta la sequenza \(S\) degli \(n-1\) precedenti segnali, e che \(a = r\).
Sia \(\sigma_n \in \lbrace A, R \rbrace\) il segnale privato che riceve l'\(n\)-esimo individuo.
Dato che stiamo assumendo che \(a = r\) avremo che
\[
    \sigma_n = A \implies \mathcal{P}(Y \vert S \cup \lbrace \sigma_n \rbrace) = \mathcal{P}(Y \vert \sigma_n) > p\\
    \sigma_n = R \implies \mathcal{P}(Y \vert S \cup \lbrace \sigma_n \rbrace) = \mathcal{P}(Y \vert \sigma_n) < p
    \]
perciò l’individuo segue il suo segnale privato, qualunque esso sia.<br />
</p>

<p>
Se invece \(a = r+1\) avremo che
\[
    \sigma_n = A \implies \mathcal{P}(Y \vert S \cup \lbrace \sigma_n \rbrace) > p\\
    \sigma_n = R \implies \mathcal{P}(Y \vert S \cup \lbrace \sigma_n \rbrace) = p
    \]
e anche in questo caso l'individuo \(n\) segue il suo segnale privato.<br />
</p>

<p>
Invece se \(a \geq r+2\) all'individuo \(n\) conviene sempre scommettere su <code>Y</code>, qualunque sia il suo segnale, scatenando così una cascata imitativa.
Simmetricamente per <code>N</code> quando \(r \geq a+2\).<br />
</p>

<p>
Quindi, individuato la condizione per la quale scatta la cascata, ci si chiede in che situazione si arriva ad avere \(a \geq r+2\) (o \(r \geq a+2\))?<br />
</p>

<p>
Fin quando i due segnali <code>A</code> ed <code>R</code> si alternano non può scattare l'herding, perché \(\vert a - r \vert \leq 1\).
Allora verrebbe da dire che quando si ottengono <span class="underline">due segnali consecutivi</span> può scattare l'herding.
Questa condizione è necessaria, ma non sufficiente.
Infatti, in una sequenza del tipo <code>ARAR...ARAA</code> due <code>A</code> consecutive bastano per scatenare la cascata imitativa per <code>Y</code>, ovvero bastano per avere \(a \geq r+2\).
Purtroppo però, nella stessa sequenza, se abbiamo due <code>R</code> consecutive non è sufficiente per far scattare una cascata imitativa di <code>N</code>.
Infatti nella sequenza <code>ARAR...ARR</code> abbiamo che \(a - r= 1\).<br />
</p>

<p>
Perciò, per essere completamente certi di ottenere una cascata imitativa, si necessita di <b>almeno 3 segnali identici consecutivi</b>!<br />
</p>

<p>
Calcoliamo ora la probabilità che una cascata si scateni entro il passo \(n\).<br />
Indichiamo sempre con \(\sigma_i \in \lbrace A, R \rbrace\) il segnale privato dell'\(i\)-esimo individuo, e siano gli eventi
</p>
\begin{align*}
  \mathcal{A} &= (\sigma_1 = \sigma_2 = \sigma_3) \vee (\sigma_2 = \sigma_3 = \sigma_4) \vee ... \vee (\sigma_{n-3} = \sigma_{n-2} = \sigma_{n-1}) \vee (\sigma_{n-2} = \sigma_{n-1} = \sigma_n)\\
      	      &= \bigvee_{1 \leq i \leq n-2} (\sigma_i = \sigma_{i+1} = \sigma_{i+2})\\
	      \\
  \mathcal{B} &= (\sigma_1 = \sigma_2 = \sigma_3) \vee (\sigma_4 = \sigma_5 = \sigma_6) \vee ... \vee (\sigma_{n-5} = \sigma_{n-4} = \sigma_{n-3}) \vee (\sigma_{n-2} = \sigma_{n-1} = \sigma_n)\\
      	      &= \bigvee_{1 \leq i \leq n/3} (\sigma_{3i-2} = \sigma_{3i-1} = \sigma_{3i})
\end{align*}
<p>
Osserviamo che \(\mathcal{B} \subseteq \mathcal{A}\), perciò \(\mathcal{P}(\mathcal{B}) \leq \mathcal{P}(\mathcal{A})\).<br />
</p>

<p>
Indichiamo ora con \(\mathcal{H}_n\) l'evento <i>"la cascata imitativa si innesca entro il passo \(n\)"</i>.
La sua probabilità sarà
\[
    \mathcal{P}(\mathcal{H}_n) \geq \mathcal{P}(\mathcal{A}) \geq \mathcal{P}(\mathcal{B})
    \]
Per la legge di De Morgan avremo che
\[
    \mathcal{P}(\lnot \mathcal{H}_n) \leq \mathcal{P}(\lnot \mathcal{B}) = \mathcal{P}(\bigwedge_{1 \leq i \leq n/3} \lnot (\sigma_{3i-2} = \sigma_{3i-1} = \sigma_{3i}))
    \]
Dato che gli eventi in \(\mathcal{B}\) sono tutti indipendenti tra di loro, abbiamo che
\[
    \mathcal{P}(\lnot \mathcal{H}_n) \leq \prod_{1 \leq i \leq n/3} \mathcal{P}(\lnot (\sigma_{3i-2} = \sigma_{3i-1} = \sigma_{3i}))
    \]
</p>

<p>
Per ogni \(i \leq n/3\) abbiamo che la probabilità dell'evento \((\sigma_{3i-2} = \sigma_{3i-1} = \sigma_{3i})\) sarà
</p>
\begin{align*} 
  \mathcal{P}(\sigma_{3i-2} = \sigma_{3i-1} = \sigma_{3i}) &= \mathcal{P}((\sigma_{3i-2} = \sigma_{3i-1} = \sigma_{3i} = A) \vee (\sigma_{3i-2} = \sigma_{3i-1} = \sigma_{3i} = R))\\
  &= \mathcal{P}(\sigma_{3i-2} = \sigma_{3i-1} = \sigma_{3i} = A) +  \mathcal{P}(\sigma_{3i-2} = \sigma_{3i-1} = \sigma_{3i} = R)\\
  &= \mathcal{P}(AAA) +  \mathcal{P}(RRR)\\
  &= \mathcal{P}(AAA) +  \mathcal{P}(RRR)\\
  &= \left[ \mathcal{P}(AAA \vert Y)\mathcal{P}(Y) + \mathcal{P}(AAA \vert N)\mathcal{P}(N)\right] + \left[ \mathcal{P}(RRR \vert Y)\mathcal{P}(Y) + \mathcal{P}(RRR \vert N)\mathcal{P}(N)\right]\\
  &= \left[ q^3p + (1-q)^3(1-p) \right] + \left[ (1-q)^3p + q^3(1-p) \right]\\
  &= 1 - 3q + 3q^2
\end{align*}

<p>
Perciò il complemento sarà
\[
    \mathcal{P}(\lnot (\sigma_{3i-2} = \sigma_{3i-1} = \sigma_{3i})) = 1 - \mathcal{P}(\sigma_{3i-2} = \sigma_{3i-1} = \sigma_{3i}) = 3q - 3q^2
    \]
</p>

<p>
Applicando questa uguaglianza per ogni \(i\) avremo che
\[
    \mathcal{P}(\lnot \mathcal{H}_n) \leq (3q - 3q^2)^{n/3}
    \]
</p>

<p>
Osserviamo in fine che \((3q - 3q^2) < 1\) per ogni \(q \in \left[0,1\right]\).
</p>

<div class="figure">
<p><img src="../images/ar-lesson12-img1.png" alt="ar-lesson12-img1.png" style="max-width:450px;" width="100%" />
</p>
<p><span class="figure-number">Figura 1: </span>\((3q - 3q^2) < 1\) per ogni \(q \in \left[0,1\right]\).</p>
</div>

<p>
Perciò possiamo concludere che la cascata imitativa si inneschera <b>quasi sicuramente</b> al crescere degli individui.
\[
    \mathcal{P}(\mathcal{H}_n) \geq 1 - (3q - 3q^2)^{n/3} \implies \lim_{n \rightarrow \infty} \mathcal{P}(\mathcal{H}_n) = 1
    \]
</p>

<p>
<b>[DISCUTERE OSSERVAZIONI FINALI&#x2026;]</b>
</p>

<hr />
</div>
</div>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Note a pi&egrave; di pagina: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1">1</a></sup> <div class="footpara"><p class="footpara">
i pedici \(g,b\) per \(v_g, v_b\) stanno ad indicare <i>good</i>, <i>bad</i> rispettivamente.
</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="date">Data: 2021-11-29 lun 00:00</p>
<p class="author">Autore: Alessandro Straziota</p>
<p class="email">Email: <a href="mailto:alessandrostr95@gmail.com">alessandrostr95@gmail.com</a></p>
<p class="date">Created: 2021-12-28 mar 18:26</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
