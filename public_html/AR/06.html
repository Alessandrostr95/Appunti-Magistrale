<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it">
<head>
<!-- 2021-11-17 mer 00:39 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>AR - Lesson 06</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Alessandro Straziota" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" href="/appunti.css" />
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2020 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="h" href=""> UP </a>
 |
 <a accesskey="H" href="/"> HOME </a>
</div><div id="content">
<h1 class="title">AR - Lesson 06</h1>
<div id="table-of-contents">
<h2>Indice</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org8596eef">1. Fenomeno Small World</a>
<ul>
<li><a href="#org6d5971f">1.1. Six Degrees of Separation</a></li>
<li><a href="#orgf28b809">1.2. The Watts-Strogatz model</a>
<ul>
<li><a href="#orgb52a002">1.2.1. Navigabilità del modello Watts-Strogatz</a></li>
</ul>
</li>
<li><a href="#org6e9c001">1.3. Un modello per la ricerca decentralizzata</a>
<ul>
<li><a href="#org160e534">1.3.1. Prestazioni della ricerca miope (decentralizzata)</a></li>
<li><a href="#orgcad3c1a">1.3.2. Ricerca miope per \(q \neq d\)</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org8596eef" class="outline-2">
<h2 id="org8596eef"><span class="section-number-2">1</span> Fenomeno Small World</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org6d5971f" class="outline-3">
<h3 id="org6d5971f"><span class="section-number-3">1.1</span> Six Degrees of Separation</h3>
<div class="outline-text-3" id="text-1-1">
<p>
Consideriamo l'esperimento dello psicologo statunitense Stanley Milgram (1967).
In tale esperimento Milgram scelse una persona <b>target</b> che risedeva dalla parte opposta degli Stati Uniti.
Dopodiché inviò una serie di lettere ad un gruppo di persone con le seguenti informazioni e regole:
</p>
<ol class="org-ol">
<li>nella lettera era specificato nome, indirizzo, occupazione e altre informazioni riguardo il target</li>
<li>chi riceveva questa lettera doveva <b>inoltrarla</b> (ovvero inviare una sola copia) ad un'altra persona, che secondo lui
si avvicinava di più al target.
Era possibile inviare la lettera ad una persona solo se la si conosceva di prima persona.</li>
</ol>

<p>
Al termine dell'esperimento Milgram osservò che circa un terzo delle lettere riuscirono ad arrivare al target, ma ancor più interessante
che tutte arrivarono mediamente in 6 passi.<br />
</p>

<p>
Questo esperimento suggerì due proprietà importanti delle reti sociali:
</p>
<ol class="org-ol">
<li>un'abbondanza di <b>cammini brevi</b> tra gli individui della rete, noto come <i>fenomeno Small World</i> (o <i>"Six Degrees of Separation"</i>).</li>
<li>tali cammini potevano facilmente essere individuati dagli individui, che altro non conoscono della struttura della rete se non il loro vicinato
ed una <i>euristica</i> che gli consenta di intuire i vicini più plausibili per i cammini.
Questo è noto come <i>fenomeno della navigabilità</i>.</li>
</ol>

<p>
Certamente un aiuto molto rilevante per la <i>navigabilità</i> è stata la presenza di alcune informazioni riguardo il target nella lettera (apparte il nome).
Per esempio se so che il target abita in un certa regione cercherò come prima cosa di inoltrare la lettera a una persona che geograficamente si avvicina.
Ancora, se so è abbastanza vicino a me e so anche che è un medico, certamente cercherò tra le mie conoscenze una persona che lavora (o che ha a che fare)
con l'ambiente sanitario (è meno probabile che mi avvicini se inoltro la lettera a un contadino).
Invece, se avessi avuto <b>solamente</b> il nome del target senza essere in grado nemmeno di individuare la sua città, molto probabilmente la lettera sarebbe stata
perduta.<br />
</p>


<p>
Per quanto riguarda l'abbondanza di cammini brevi invece una possibile motivazione <span class="underline">intuitiva</span> è la seguente:
supponiamo di avere conoscere in maniera diretta 100 persone, e che tali persone conoscono direttamente altre 100 persone.
Allora con due "hop" posso raggiungere \(100 \cdot 100 = 10000\) altre persone.
E se a loro volta gli amici dei miei amici conoscono 100 perso, in tre "hop" potrò raggiungere altri \(100 \cdot 100 \cdot 100 = 1000000\) persone, e così via&#x2026;
</p>


<div class="figure">
<p><img src="../images/ar-lesson06-img1.png" alt="ar-lesson06-img1.png" style="max-width:500px;" width="100%" />
</p>
<p><span class="figure-number">Figura 1: </span>Crescita puramente esponeziale delle conoscenze.</p>
</div>

<p>
Purtroppo però questo ragionamento è inconsistente, in quanto si fa un'assunzione molto forte, ovvero che ogni proprio amico conosce altre 100 persone <b>distinte</b>.
In un conteso reale è però poco plausibile questa proprietà: se sono amico stretto di due persone è <i>motlo probabile</i> che prima o poi essi si conoscano e diventino
a loro volta conoscenti.
Per esempio le reti di conoscenze dei <i>social networks</i> mostrano la presenza di una quantità elevata di <b>triangoli</b> tra gli individui, a conferma di quanto osservato.
La caratteristica di una rete di avere molti triangoli è detta <b>chiusura triadica</b> (<b>triadic closure</b>), la quale diminuisce di molto il numero di individui raggiungibili
con percorsi brevi rispetto al modello con crescita esponenziale.
</p>


<div class="figure">
<p><img src="../images/ar-lesson06-img2.png" alt="ar-lesson06-img2.png" style="max-width:500px;" width="100%" />
</p>
<p><span class="figure-number">Figura 2: </span>La chiusura triadica diminuisce di molto il numero di persone raggiungibili con percorsi brevi.</p>
</div>
</div>
</div>


<div id="outline-container-orgf28b809" class="outline-3">
<h3 id="orgf28b809"><span class="section-number-3">1.2</span> The Watts-Strogatz model</h3>
<div class="outline-text-3" id="text-1-2">
<p>
Nel 1998 Duncan Watts and Steve Strogatz proposero un modello generativo di grafi aleatori che soddisfano due proprietà precedentemente viste: la presenza
di numerosi triangoli e la presenza di cammini brevi che collegano le entità della rete.<br />
</p>

<p>
Il grafo generato in accordo col <b>modello Watts-Strogatz</b> è composto da due componenti:
</p>
<ul class="org-ul">
<li>una componente <b>deterministica</b> che consiste in una <b>griglia bidimensionale</b></li>
<li>una componente <b>aleatoria</b> sovrastante</li>
</ul>

<p>
La griglia bidimensionale è un sottoinsieme di \(\mathbb{N}^2\), i cui <i>punti</i> sono i nodi del grafo.
Nella griglia ogni nodo ha un acro con i suoi vicini posti a destra, sinistra, sopra, sotto e in diagonale.
Più formalmente, fissato un \(n \in \mathbb{N}\):
\[
   V \equiv \lbrace (i,j) \in \mathbb{N}^2 | 0 \leq i < n \land 0 \leq j < n \rbrace\\
   E_1 \equiv \lbrace \lbrace (i,j), (a,b) \rbrace \in V^2 | \left[ a \equiv_n i+\alpha \land b \equiv_n j+\beta \right] \; \forall \alpha,\beta = -1, 0, 1 \rbrace
   \]
Se si fa attenzione alla definizione di \(E_1\) (ovvero l'insieme degli archi della componente deterministica), si può vedere che la griglia ha una sorta di <i>periodicità</i>,
ovvero i nodi a un bordo della griglia sono collegati ai nodi sul bordo opposto.
In questa maniera otteniamo un primo grafo con un'alta quantità di <i>triangoli</i> (prima proprietà desiderata).<br />
</p>

<p>
Per costruire la componente aleatoria fissiamo un \(k>1\), e per ogni nodo \(v \in V\) esso aggiungerà come ulteriori vicini altri \(k\) nodi scelti <span class="underline">uniformemente a caso</span>.
</p>


<div class="figure">
<p><img src="../images/ar-lesson06-img3.png" alt="ar-lesson06-img3.png" style="max-width:450px;" width="100%" />
</p>
<p><span class="figure-number">Figura 3: </span>Costruzione modello Watts-Strogatz</p>
</div>

<p>
Si può osservare una certa <i>dicotomia</i> tra gli archi deterministici e quelli aleatori:
</p>
<ol class="org-ol">
<li>gli archi deterministici rappresentano un <b>legame forte</b> tra i nodi (<b>strong tie</b>), infatti tra due nodi legati da un arco deterministico esistono sempre dei triagoli.</li>
<li>gli archi aleatori rappresentano invece delle conoscenze "alla lontana", e in quanto tale un <b>legame debole</b> (<b>weak tie</b>). Infatti è molto poco probabile trovare triangoli nella componente
aleatoria (a meno che \(k\) non sia <span class="underline">molto</span> grande).<br /></li>
</ol>

<p>
A questo punto è doveroso chiedersi se effetivamente esistono cammini brevi tra i nodi della rete.
Intuitivamente parlando, se si considerano cammini composti dai soli archi aleatori, è poco probabile incontrare due volte uno stesso nodo in brevi distanze.
Perciò, nella compononete aleatoria la crescita dei <span class="underline">nuovi</span> nodi vicini è più simile al modello con crescita esponenziale (vedi Img. 1).<br />
</p>

<p>
Successivamente Bollobàs &amp; Ching diedero una dimostrazione formale a questo fenomeno. Più precisamente dimostrarono la presenza di cammini brevi in un modello
con molta meno <i>randomness</i>.
Consideriamo un nuovo modello simile a quello Watts-Strogatz, dove però solo un nodo su \(k\) ha archi random, e il numero di archi random è pari a 1.
Partizioniamo poi la rete in "<b>città</b>" di \(k \times k\) individui, e consideriamo il fenomeno small-world a livello di città.
Certamente ogni città avrà mediamente \(k\) archi random, e inoltre ogni coppia di nodi \(u,v\) di una stessa città sarà connessa da un cammino breve di lunghezza <i>al più</i> \(2k\).
Venne dimostrato che per trovare un cammino relativamente corto tra due nodi \(u,v\) di due città differenti, basta che
\(u\) raggiunga un nodo \(w\) nella stessa città (in al più \(2k\)) passi, e poi tramite pochi salti passare da dua città all'altra
fino ad arrivare alla città di \(v\).<br />
</p>

<p>
In conclusione, anche con un piccolo ammontare di casualità, il modello Watts-Strogatz cattura il fenomeno di "mondo piccolo".<br />
</p>
</div>

<div id="outline-container-orgb52a002" class="outline-4">
<h4 id="orgb52a002"><span class="section-number-4">1.2.1</span> Navigabilità del modello Watts-Strogatz</h4>
<div class="outline-text-4" id="text-1-2-1">
<p>
Assodato che nel modello Watts-Strogatz esistono cammini relativamente corti tra i nodi della rete, quello che ci si chiede
è se tali cammini corti sono facilmente rintracciabili dai nodi, che conoscono solamente il loro vicinato e non la struttura dell'intera rete.<br />
</p>

<p>
Supponiamo che un nodo \(u\) deve mandare un messaggio a un nodo \(v\) del quale conosce solamente le sue coordinate sulla griglia geometrica.
Il nodo \(u\) potrebbe mandare in broadcast il messaggio a tutti i suoi vicini (che sono 8 o 9), e chiedere a loro di inviare
il messaggio a tutti i loro vicini.
Questo metodo è noto come <code>Flooding</code> dei messaggi, ed è il metodo più veloce per raggiungere il nodo \(v\) (in quanto equivale
ad una <i>visita in ampiezza</i>).
Il problema è che dopo \(h\) salti, ci sarebbero circa \(8^h\) messaggi in circolazione, oltre al fatto che sarebbe scortese
chiedere di inviare 8 messaggi ai propri vicini.<br />
</p>

<p>
Vorremmo un modo per trovare un cammino non troppo lungo tra \(u\) e \(v\) in modo da trasmettere una sola copia del messaggio,
e non un numero esponenziale, un po' come fecero le persone che parteciparono all'esperimento di Milgram.<br />
</p>

<p>
Purtroppo fare questo tipo di ricerca <b>miope</b><sup><a id="fnr.1" class="footref" href="#fn.1">1</a></sup> in un modello Watts-Strogatz non è possibile.
Per esempio il nodo \(u\) potrebbe pensare di mandare il messaggio al suo vicino che più si avvicina alla destinazione \(v\).
Questo però potrebbe non essere il modo miglio per raggiongere \(v\).
Per esempio potrebbe esistere un nodo \(w\) vicino di \(u\) che si allontana di 1 rispetto a \(v\) nella griglia deterministica,
ma che però è direttamente collegato a \(v\) tramite la componente aleatoria.
</p>


<div class="figure">
<p><img src="../images/ar-lesson06-img4.png" alt="ar-lesson06-img4.png" style="max-width:450px;" width="100%" />
</p>
<p><span class="figure-number">Figura 4: </span>Controesempio appena descritto</p>
</div>

<p>
Purtroppo però \(u\) non può in alcun modo sapere che conviene inviare il messagio a \(w\), in quanto conosce <span class="underline">solo il suo vicinato</span> e non quello di \(w\).
Inoltre è stato anche dimostrato<sup><a id="fnr.2" class="footref" href="#fn.2">2</a></sup> con questo tipo di ricerca (nota come <b>ricerca decentralizzata</b>), non solo non c'è
nessuna garanzia di trovare un cammino corto, ma mediamente i cammini trovati sono <i>molto</i> più lunghi dei cammini minimi che
esistono tra mittente e destinatario.<br />
</p>

<p>
Sostanzialmente il problema è che gli archi random della componente aleatoria sono "troppo" casuali per dare un supporto alla ricerca decentralizzata.
Infatti in un contesto sociale reale, è molto poco probabile che due persone <i>totalmente a caso</i> entrino in contatto.
È invece più probabile avere archi casuali tra persone più vicine fisicamente, anziché tra persone molto lontane.
</p>

<p>
Quindi possiamo dire che questo modello non è navigabile, e quindi non rispecchia le caratteristiche volute.
</p>
</div>
</div>
</div>


<div id="outline-container-org6e9c001" class="outline-3">
<h3 id="org6e9c001"><span class="section-number-3">1.3</span> Un modello per la ricerca decentralizzata</h3>
<div class="outline-text-3" id="text-1-3">
<p>
Vogliamo quindi definire un modello di generazione di reti sociali che in qualche modo consenta una ricerca decentralizzata
di caminni che non siano troppo più lunghi dei cammini minimi.<br />
</p>

<p>
Basandoci sull'osservazione precedentemente fatta che è poco probabile avere archi random <span class="underline">totalmente a caso</span>, possiamo
definire un modello che aggiunge un parametro che controlla il <i>range di copertura</i> degli archi random<sup><a id="fnr.3" class="footref" href="#fn.3">3</a></sup>.<br />
</p>

<p>
Più formalmente siano due nodi \(u,v\) con distanza \(d(u,v)\) nella <i>componente deterministica</i> sottostante, e sia una costante
\(c \geq 0\) detta <b>esponente di clustering</b>.
Perciò la probabilità che nella componente aleatoria esista l'arco \((u,v)\) è proporzionale alla quantità \(d(u,v)^{-q}\),
più precisamente
\[
   \mathcal{P}( (u,v) \in E_2 ) = \frac{1}{Z_u} \cdot \frac{1}{d(u,v)^q}
   \]
dove chiamiamo per comodità \(E_2\) l'insieme di archi random, e \(Z_u\) è un <b>fattore di normalizzazione</b> definito come
\[
   Z_u = \sum_{v \in V \setminus \lbrace v \rbrace} \frac{1}{d(u,v)^q}
   \]
</p>

<p>
Il fattore di normalizzazione è detto tale in quanto
\[
   \sum_{v \in V \setminus \lbrace v \rbrace} \mathcal{P}( (u,v) \in E_2 ) = 1
   \]
</p>

<p>
Se consideriamo come componente deterministica una griglia <i>simmetrica e periodica</i> come nel modello Watts-Strogatz,
allora il fattore di normalizzazione sarà un certo \(Z\) uguale per tutti i nodi.
Questo in generale è vero per ogni componente deterministica completamente simmetrica.
D'ora in poi si farà riferimento a modelli che presentano questo livello di simmetria.<br />
</p>

<p>
Osserviamo che quando \(q=0\) gli archi random sono totalmente casuali, in quanto la probabilità che tale arco esista è uguale per tutti<sup><a id="fnr.4" class="footref" href="#fn.4">4</a></sup>,
risultando quindi uguale al modello Watts-Strogatz.
Quando invece la \(q\) è molto grande sostanzialmente la probabilità di trovare archi random molto lunghi diventa molto piccola,
perciò la componente aleatoria diventa sempre più simile alla sola componente deterministica.
Ricapitolando quando \(q\) è piccolo la casualità è tanta, quando \(q\) è grande la casualità è poca.
</p>


<div class="figure">
<p><img src="../images/ar-lesson06-img5.png" alt="ar-lesson06-img5.png" style="max-width:550px;" width="100%" />
</p>
</div>

<p>
Intuitivamente al variare di \(q\) esistono valori migliori e valori perggiori per la ricerca decentralizzata.
Già sappiamo che per \(q=0\) il valore è pessimo.
È possibile però dimostrare, che data una griglia \(d\)-dimensionale <b>wrapped</b><sup><a id="fnr.5" class="footref" href="#fn.5">5</a></sup>, allora il componente di
clustering ottimale sarà esattamente \(q = d\).<br />
</p>

<p>
Cerchiamo ora di dare una spiegazione intuitiva a questo fenomeno.
Riconsideriamo nuovamente l'esperimento di Milgram, dove però abbiamo il mittente <code>A</code> che vive negli Stati Uniti mentre
il destinatario <code>B</code> vive a Roma quartiere Garbatella.
Certamente la prima cosa che farebbe <code>A</code> sarebbe quella di inviare la lettera qunatomeno ad una persona che vive in Europa.
Anche se <code>A</code> non ha amici diretti in Europa a cui inviare la lettera, passandola ad altri amici negli USA troverà brevemente
qualcuno che ha amici che vivono oltre oceano.
Per semplicità assumiamo che <code>A</code> invii direttamente la lettera ad un suo amico <code>C</code> che vive a Mosca.
A sua volta <code>C</code> cerca tra i suoi amici qualcuno che abiti almeno in Europa Occidentale.
Da <code>C</code> la lettera passa a <code>D</code> che vive a Parigi.
Per fortuna <code>D</code> ha un amico in Italia che però vive a Perugia, e quindi la lettera finisce in Umbira.
<code>D</code> si ricorda di avere un lontano parente <code>E</code> nel Lazio, a cui invia la lettera.
Dopodiché <code>E</code> invia la lettera ad un suo collega <code>F</code> che abita a Roma Centocelle, il quale a sua volta
invierà la lettera a un amico <code>G</code> che abita a Garbatella.
Di li, sicuramente in un numero non esagerato di passi la lettera arriva a <code>B</code>.<br />
</p>

<p>
Come si può intuire, il processo di ricerca decentralizzata procede per <b>scale di risoluzione</b>.
Infatti, anche se per pochi salti la lettera percorre relativamente poca distanza, presto farà un salto che riduce
drasticamente la distanza con la destinazione.<br />
</p>

<p>
<b>[aggiungere immagini]</b><br />
</p>

<p>
Consideriamo una semplice griglia <span class="underline">bidimensionale</span> (con \(d = 2\)) wrapped, e partizioniamo i nodi in base alla distanza dal mittente \(u\).
Più precisamente partizioniamo i nodi i gruppi in cui la distanza cresce esponenziale, ovvero i nodi da \(u\) tra 2 e 4, poi
tra 4 e 8, tra 8 e 16, tra 16 e 32, &#x2026;, tra \(2^h\) e \(2^{h+1}\).
Dato che i punti in una circonferenza crescono come il quadrato del raggio, avremo che i nodi nell'intervallo tra \(2^h\) e \(2^{h+1}\)
sarà proporzionale a \(2^{2h}\).
Infatti
\[
   \vert \lbrace x \in V \vert 2^h \leq d(u,x) < 2^{h+1} \rbrace \vert \approx (2^{h+1})^2\pi - (2^h)^2\pi = 4\pi 2^{2h} - \pi 2^{2h} = 3\pi 2^{2h} 
   \]
</p>

<p>
Consideriamo l'indice di clustering ottimo per la griglia bidimensionale, ovvero \(q=2\).
Preso un nodo \(x\) nell'intervallo tra \(2^h\) e \(2^{h+1}\), la probabilità che esista un arco random tra \(u\) e \(x\) è proporzionale
proprio \(2^{-2h}\), ovvero 1 diviso la distanza tra \(u\) e \(x\) che compresa tra \(2^h\) e \(2^{h+1}\), il tutto elevato a \(q\) che è pari a 2.<br />
</p>

<p>
Assodato che la probabilità che \(u\) abbia un arco random con un nodo fissato \(x\) nell'intervallo \(2^h,2^{h+1}\) e proporzionale a \(2^{-2h}\),
e sapendo che in tale blocco ci sono un numero di nodi proporzionale proprio a \(2^{2h}\), possiamo affermare che la probabilità
che esista un arco random tra \(u\) e un nodo qualsiasi dell'intervallo \(2^h,2^{h+1}\) è una probabilità <b>costante</b>.
Specifichiamo perché costante:
Sia l'evento \(\mathcal{E}_x\) che occorre se esiste l'arco random tra \(u\) e il nodo \(x\) a distanza \(2^h \leq d(u,x) < 2^{h+1}\).
Sappiamo che tale evento occore con probabilità
\[
   \mathcal{P}(\mathcal{E}_x) \propto d(u,x)^{-2} \propto 2^{-2h}
   \]
Sia quindi l'evento \(\mathcal{E}\) che occorre quando esiste un arco random che collega \(u\) all'intervallo desiderato.
Tale probabilità sarà pari a
</p>
\begin{align*}
\mathcal{P}(\mathcal{E})
\textbf{(1)} &= \mathcal{P}(\bigcup_{x : 2^h \leq d(u,x) < 2^{h+1}} \mathcal{E}_x)\\
&= \sum_{x : 2^h \leq d(u,x) < 2^{h+1}} \mathcal{P}(\mathcal{E}_x)\\
&\approx |C_{2^{h+1}}(u) - C_{2^h}(u)| \cdot \mathcal{P}(\mathcal{E}_x)\\
&= \alpha 2^{2h} \cdot \beta 2^{-2h}\\
&= \gamma
\end{align*}
<p>
per qualche costante \(\alpha, \beta, \gamma\).
Specifichiamo che \(C_r(u)\) è il cerchio di raggio \(r\) centrato in \(u\), mentre l'uguaglianza <b>(1)</b> è deta dal fatto che tutti
gli eventi del tipo \(\mathcal{E}_x\) sono mutuamente disgiunti.<br />
</p>

<p>
L'ultimo risultato è molto forte, in quanto suggerisce che la probabilità che un arco random che parta da \(u\) consenta un salto
di risoluzione è <b>indipendente</b> dalla risoluzione, che sia \(2^4\) o \(2^{100}\).
Ciò implica che i weak ties sono distribuiti in maniera <b>uniforme</b> tra le risoluzioni, ammesso che poniamo \(q\) pari al valore
ottimale \(d\).
</p>
</div>

<div id="outline-container-org160e534" class="outline-4">
<h4 id="org160e534"><span class="section-number-4">1.3.1</span> Prestazioni della ricerca miope (decentralizzata)</h4>
<div class="outline-text-4" id="text-1-3-1">
<p>
Nella precedente sezione abbiamo dato un'idea intuitiva del perché una distribuzione inversamente quadratica dei weak ties rispetto
alle distanze rende la ricerca decentralizzata possibile.<br />
</p>

<p>
Per semplicità verrà fatta un'analisi rigorosa (e non intuitiva) di questo fenomeno su una griglia 1-dimensionale, ovvero un <i>anello</i>.
</p>


<div class="figure">
<p><img src="../images/ar-lesson06-img6.png" alt="ar-lesson06-img6.png" style="max-width:300px;" width="100%" />
</p>
<p><span class="figure-number">Figura 6: </span>Anello con random links.</p>
</div>

<p>
All'interno dell'anello ogni nodo \(v\) ha esattamente 2 vicini, detti <b>contatti locali</b> (o <b>local links</b>), e nella compontente aleatoria da ogni nodo
\(v\) parte un arco diretto casuale \((v,w)\), detto <b>contatto a lunga distanza</b> (o <b>long-range link</b>), che esiste con probabilità \(d(v,w)^{-1}\).<br />
</p>

<p>
Ricordiamo che la <b>ricerca miope</b> consiste essenzialmente nel passare il messaggio al nodo vicino che più si avvicina al destinatario.
Considerando la precedente figura, supponiamo che il nodo <code>a</code> voglia inviare il messaggio al nodo <code>i</code> dalla parte opposta dell'anello.
Tra i suoi vicini ci sono <code>b</code> e <code>p</code> collegati da <i>local links</i> e il nodo <code>d</code> collegato da un <i>long-range link</i>.
Tra i tre, il più vicino a <code>i</code> è il nodo <code>d</code>, e quindi <code>a</code> gli passa il messaggio.
Dopodiché <code>d</code> passa il nodo a <code>e</code> che è il suo vicino più prossimo alla destinazione, che a sua volta invia il messaggio al nodo <code>f</code> (per gli stessi ragionamenti fatti fin ora).
Infine <code>f</code> inoltra il messaggio attraverso il un <i>long-range link</i> al nodo <code>h</code>, che è recapita il messaggio al destinatario in quanto suo
diretto vicino.<br />
</p>


<div class="figure">
<p><img src="../images/ar-lesson06-img7.png" alt="ar-lesson06-img7.png" style="max-width:300px;" width="100%" />
</p>
<p><span class="figure-number">Figura 7: </span>Risultato della ricera miope da a ad i</p>
</div>

<p>
Ovviamente questo non è un cammino minimo, per esempio se <code>a</code> avesse inviato il messaggio a <code>b</code> anziché a <code>d</code>, esso sarebbe arrivato
a destinazione in soli 3 passi.
Però sappiamo che <code>a</code> non ha alcuna informazione oltre alla visione del suo vicinato, e il cammino risultate dalla ricerca miope
è abbastanza corto da essere un risultato più che accettabile con le poche informazioni a disposizione.<br />
</p>

<p>
Scelti una mittente \(s\) e un destinatario \(t\) a caso, definiamo la v.a. \(X\) come il la lunghezza di un cammino da \(s\) a \(t\) risultante
dalla ricerca miope, e sia \(\mathbb{E}\left[ X \right]\) la lunghezza <span class="underline">media</span> di tali cammini.<br />
Considerando una ricerca miope da \(s\) a \(t\), diremo che essa si trova della fase \(j\) se il messaggio si trova ad una distanza
compresa tra \(2^j\) e \(2^{j+1}\) dal destinatario.
</p>


<div class="figure">
<p><img src="../images/ar-lesson06-img8.png" alt="ar-lesson06-img8.png" style="max-width:300px;" width="100%" />
</p>
</div>

<p>
Osserviamo che le fasi possono essere al più \(\log_{2}{n}\).<br />
</p>

<p>
Possiamo scrivere \(X\) come la somma delle v.a. \(X_1, X_2, ..., X_{log{n}}\) dove \(X_i\) è la lunghezza complessiva del cammino lungo
la fase \(i\)
\[
    X = X_1 + X_2 + ... + X_{log{n}}
    \]
Per linearità avremo che
\[
    \mathbb{E}\left[ X \right] = \mathbb{E}\left[ X_1 + X_2 + ... + X_{log{n}} \right] = \mathbb{E}\left[ X_1 \right] +  \mathbb{E}\left[ X_2 \right] + ... +  \mathbb{E}\left[ X_{log{n}} \right]
    \]
</p>

<p>
Di seguito il temoremo che stima \(\mathbb{E}\left[ X \right]\) <br />
</p>

<p>
<b>THM</b> Sia \(\mathbb{E}\left[ X \right]\) la lunghezza media dei cammini risultati dalla ricerca miope tra una qualsiasi coppia di nodi, allora
\[
    \mathbb{E}\left[ X \right] \in O(\log^2{n})
    \]
</p>

<p>
Per dimostrare il precedente teorema basta dimostrare che \(\mathbb{E}\left[ X_i \right] \in O(\log{n})\), per ogni fase \(i\).
Prima di procedere alla dimostrazione del teorema però è necessario fare alcune considerazioni sul fattore di normalizzazione \(Z\) del modello.
</p>

<p>
Sappiamo che \(Z\) è pari alla somma di tutti i \(d(u,v)^{-1}\) per ogni \(u \neq v\).
Però sappiamo che in un anello ci sono esattamente 2 nodi a distanza 1 da \(u\), 2 a distanza 2, 2 a distanza 3, &#x2026;, 2 a distanza \(n/2\) (assumendo senza perdita di generalità che \(n\) sia pari).
Perciò avremo che
\[
    Z = 2\left( 1 + \frac{1}{2} + \frac{1}{3} + ... + \frac{1}{n/2} \right)
    \]
Sappiamo inoltre approssimmare la sommatoria in parentesi come
\[
    1 + \frac{1}{2} + \frac{1}{3} + ... + \frac{1}{n/2} \leq 1 + \int_{1}^{n/2} \frac{1}{x} \,dx =  1 + \ln{(n/2)}
    \]
Tornando a \(Z\) avremo che
</p>
\begin{align*}
Z &\leq 2(1 + \ln{(n/2)})\\
&\leq 2(1 + \log_2{(n/2)})\\
&= 2 + 2\log_2{(n/2)}\\
&= 2 + 2\log_2{(n)} - 2\log_2{(2)} = 2\log_2{(n)}
\end{align*}

<p>
Perciò la probabilità che esista un random edge tra \(u\) e \(v\) sarè
\[
    \mathcal{P}((u,v) \in E_2) = \frac{1}{Z}d(u,v)^{-1} \geq  \frac{1}{2\log{n}}d(u,v)^{-1}
    \]
Procediamo ora alla dimsotrazione del teorema
</p>

<p>
<b>Proof THM:</b> 
Siano i nodi \(s,t\) rispettivamente il nodo <i>mittente</i> e il nodo <i>destinatario</i>.
Abbiamo partizionato i nodi in base a distanze dalla sorgente \(t\) che si <span class="underline">dimezzano</span>, ovvero abbiamo definito
la fase \(j\) in cui il messaggio appartiene a un nodo \(u\) con distanza
\[
    \frac{d(s,t)}{2^{j+1}} \leq d(u,t) < \frac{d(s,t)}{2^j}
    \]
Certamente è vero che se esiste un arco \((u,v)\) tale che
\[
    d(v,t) \leq \frac{d(u,t)}{2} < \frac{1}{2}\frac{d(s,t)}{2^j} = \frac{d(s,t)}{2^{j+1}}
    \]
allora la fase \(j\) termina.<br />
</p>

<p>
Abbiamo quindi un limite inferiore alla probabilità che la fase \(j\) termini
</p>
\begin{align*}
  \mathcal{P}(\mbox{la fase } j \mbox{ termina})
  &= \mathcal{P}(\exists (u,v) \in E : d(v,t) < \frac{d(s,t)}{2^{j+1}})\\
  &\geq \mathcal{P}(\exists (u,v) \in E : d(v,t) \leq \frac{d(u,t)}{2})
\end{align*}

<p>
Definiamo ora con \(I\) l'insieme di tutti i nodi a distanza da \(t\) non più di \(\frac{d(u,t)}{2}\), ovvero
\[
    I \equiv \lbrace x \in V : d(x,t) \leq \frac{d(u,t)}{2} \rbrace
    \]
</p>

<p>
Ricordando che \(E_1\) è l'insieme di archi della componente deterministica ed \(E_2\) gli archi di quella aleatoria, avremo quindi che
</p>
\begin{align*}
  \mathcal{P}(\exists (u,v) \in E : d(v,t) \leq \frac{d(u,t)}{2})
  &= \mathcal{P}(\exists v \in I : (u,v) \in E)\\
  &= \mathcal{P}(\exists v \in I : (u,v) \in E_1 \cup (u,v) \in E_2)\\
  &= \sum_{v \in I} \mathcal{P}((u,v) \in E_1 \cup (u,v) \in E_2)\\
  &= \sum_{v \in I} \mathcal{P}((u,v) \in E_1) + \mathcal{P}((u,v) \in E_2)\\
  &\geq \sum_{v \in I} \mathcal{P}((u,v) \in E_2) = \sum_{v \in I} \frac{1}{Z}\frac{1}{d(u,v)}
\end{align*}

<p>
Diamo ora una stima alla distanza \(d(u,v)\).
Certamente \(u\) può raggiungere \(v\) tramite un cammino del tipo \(u \leadsto t \leadsto v\), e questo cammino sarà
lungo <b>almeno</b> \(d(u,v)\)
\[
    d(u,v) \leq d(u,t) + d(t,v) = d(u,t) + d(v,t) \leq d(u,t) + \frac{d(u,t)}{2} = \frac{3d(u,t)}{2}
    \]
perciò, per ogni \(v \in I\) avremo che
</p>
\begin{align*}
  \sum_{v \in I} \mathcal{P}((u,v) \in E_2)
  &= \sum_{v \in I} \frac{1}{Z}\frac{1}{d(u,v)}\\
  &\geq \sum_{v \in I} \frac{1}{Z}\frac{2}{3d(u,t)}\\
  (Z \leq 2\ln{n}) &\geq \sum_{v \in I} \frac{1}{2\ln{n}}\frac{2}{3d(u,t)}\\
  &= \sum_{v \in I} \frac{1}{3d(u,t)\ln{n}}\\
  &= \frac{|I|}{3d(u,t)\ln{n}}
\end{align*}

<p>
Ora dobbiamo stimare \(|I|\).
Sappiamo che in \(I\) ci sono tutti quei nodi a distanza al più \(d(u,t)/2\), che siano dal lato destro o sinistro.
Per definizione dobbiamo contare anche \(t\), in quanto \(d(t,t) = 0 \leq d(u,t)/2\).
Avremo quindi
\[
    \vert I \vert = \lfloor \frac{d(u,t)}{2} \rfloor + \lfloor \frac{d(u,t)}{2} \rfloor + 1 \geq \frac{d(u,t)-1}{2} + \frac{d(u,t)-1}{2} + 1 = \frac{d(u,t)}{2}
    \]
perciò
\[
    \sum_{v \in I} \mathcal{P}((u,v) \in E_2) \geq \frac{d(u,t)}{3d(u,t)\ln{n}} = \frac{1}{3\ln{n}}
    \]
</p>

<p>
Perciò l'evento complementare, ovvero l'evento che la fase \(j\) non termina se siamo nel nodo \(u\) è pari a \(1 -  \frac{1}{3\ln{n}}\).
Possiamo ora ricavare la probabilità che la fase \(j\) non termini entro \(h\) passi come segue
\[
    \mathcal{P}(X_j \geq h) \leq \left( 1 -  \frac{1}{3\ln{n}} \right)^h
    \]
</p>

<p>
Per conculdere non resta che calcolare \(\mathbf{E}\left[ X_j \right]\).
Iniziamo col comporre tale fattore in una sommatoria
</p>
\begin{align*}
  \mathbf{E}\left[ X_j \right]
  &= 1 \cdot \mathbf{P}( X_j = 1 ) + 2 \cdot \mathbf{P}( X_j = 2 ) +  3 \cdot \mathbf{P}( X_j = 3 ) + ... + \frac{n}{2} \cdot \mathbf{P}( X_j = \frac{n}{2} )\\
  &= \mathbf{P}( X_j \geq 1 ) + 1 \cdot \mathbf{P}( X_j = 2 ) +  2 \cdot \mathbf{P}( X_j = 3 ) + ... + \left(\frac{n}{2} - 1 \right) \cdot \mathbf{P}( X_j = \frac{n}{2} )\\
  &= \mathbf{P}( X_j \geq 1 ) + \mathbf{P}( X_j \geq 2 ) +  1 \cdot \mathbf{P}( X_j = 3 ) + ... + \left(\frac{n}{2} - 2 \right) \cdot \mathbf{P}( X_j = \frac{n}{2} )\\
  &\vdots\\
  &= \mathbf{P}( X_j \geq 1 ) + \mathbf{P}( X_j \geq 2 ) + \mathbf{P}( X_j \geq 3 ) + ... + \mathbf{P}( X_j \geq \frac{n}{2} )\\
  &= \sum_{1 \leq h \leq n/2} \mathbf{P}( X_j \geq h )
\end{align*}
<p>
dove \(n/2\) è il massimo valore che può assumere \(X_j\) in quanto \(n/2\) è la distanza massima tra due nodi.<br />
</p>

<p>
A questo punto possiamo stimare il valor medio della durata della fase \(j\) come
</p>
\begin{align*}
  \mathbf{E}\left[ X_j \right]
  &= \sum_{1 \leq h \leq n/2} \mathbf{P}( X_j \geq h )\\
  &\leq \sum_{1 \leq h \leq n/2} \left( 1 -  \frac{1}{3\ln{n}} \right)^h\\
  &\leq \sum_{h \geq 1}^{\infty} \left( 1 -  \frac{1}{3\ln{n}} \right)^h\\
  &= \frac{1}{1 - \left( 1 -  \frac{1}{3\ln{n}} \right)} = 3\ln{n} \in O(\log{n})
\end{align*}

<p>
Di conseguenza l'ipotesi del teorema
\[
    \mathbf{E}\left[ X \right] = \sum_{j = 1}^{\log_2{n}} \mathbf{E}\left[ X_j \right] \in O(\log^2{n})
    \]
\(\square\).
</p>
</div>
</div>

<div id="outline-container-orgcad3c1a" class="outline-4">
<h4 id="orgcad3c1a"><span class="section-number-4">1.3.2</span> Ricerca miope per \(q \neq d\)</h4>
<div class="outline-text-4" id="text-1-3-2">
<p>
Prendiamo il caso \(d = 1\) e \(q = 0\).
Con \(q = 0\), la probabilità di avere l'arco random \((u,v)\) sarà pari a \(1/Z\).
\[
    \mathcal{P}((u,v) \in E) = \frac{1}{Z}\frac{1}{d(u,v)^0} = \frac{1}{Z}
    \]
Osservaimo inoltre che \(Z\) sarà pari a
\[
    Z = \sum_{v \neq u}\frac{1}{d(u,v)^0} = n - 1
    \]
</p>

<p>
Quindi la probabilità di avere un arco random sarè \(\frac{1}{n-1} > \frac{1}{n}\).<br />
</p>

<p>
Definiamo ora l'insieme \(R\) di nodi a distanza <span class="underline">al più</span> \(\sqrt{n}\) dal destinatario \(t\)
\[
    R \equiv \lbrace x \in V : d(x,t) \leq \sqrt{n} \rbrace
    \]
</p>

<p>
Prendiamo il mittente \(s\) fuori da \(R\), avremo che la probabilità di entrare in \(R\) tramite un arco random \((u,v)\) sarà
</p>
\begin{align*}
  \forall u \not\in R\\
  \mathcal{P}(\exists (u,v) \in (R, E-R))
  &= \sum_{v \in R} \mathcal{P}( (u,v) \in E_2 )\\
  &> \sum_{v \in R} \frac{1}{n}\\
  &= \frac{|R|}{n} = \frac{2\sqrt{n}}{n} = \frac{2}{\sqrt{n}}
\end{align*}

<p>
Sia quindi \(Y\) la v.a. che indica quanti passi ci vogliono per raggiungere \(R\) partendo da \(s\), con probabilità
\[
    \mathcal{P}(Y \geq h) < \left( 1 - \frac{2}{\sqrt{n}} \right)^h
    \]
con media
\[
    \mathbf{E}\left[ Y \right] = \sum_h \mathbf{P}( Y ) \leq \frac{1}{1 - \left( 1 - \frac{2}{\sqrt{n}} \right)} =  \frac{\sqrt{n}}{2}
    \]
e questo di per se è già un tempo esponenzialmente più grande del tempo che ci impiegherebbe l'intera ricerca miope nel caso \(q=1\).<br />
</p>

<p>
D'altro canto, se \(q > 1\), avremo che gli archi random sono più corti rispetto al caso \(q=1\), perciò la ricerca miope non migliora.
Addirittura per \(q\) abbastanza grande la rete tende ad essere composta dalla sola componente deterministica.<br />
</p>

<p>
Di seguito un teorema che racgiude tutti questi raggionamenti
</p>

<p>
<b>THM</b> sia \(X\) la variabile aleatoria che indica la lunghezza del cammino trovato dalla ricerca miope su un anello di \(n\) nodi.
Comunque si sceglie un \(q \neq 1\) esistono sempre due costanti \(\alpha_q\) e \(c_q\) tali che
\[
    \mathbf{E}\left[ Y \right] \geq a_q \cdot n^{c_q}
    \]
</p>

<p>
Ribadendo che il tutto vale nel caso in cui la componente deterministica sia un anello di \(n\) nodi, si possono estendere
tutti i raggionamenti anche per un qualsiasi \(d > 1\), a scapito di calcoli più complessi.
</p>
</div>
</div>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Note a pi&egrave; di pagina: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1">1</a></sup> <div class="footpara"><p class="footpara">
ovvero quando i nodi conoscono solamente il proprio vicinato.
</p></div></div>

<div class="footdef"><sup><a id="fn.2" class="footnum" href="#fnr.2">2</a></sup> <div class="footpara"><p class="footpara">
Klinberg, 2000.
</p></div></div>

<div class="footdef"><sup><a id="fn.3" class="footnum" href="#fnr.3">3</a></sup> <div class="footpara"><p class="footpara">
ovvero la distanza nella griglia deterministica sottostante tra le estremità dei random edges.
</p></div></div>

<div class="footdef"><sup><a id="fn.4" class="footnum" href="#fnr.4">4</a></sup> <div class="footpara"><p class="footpara">
probabilità uniforme.
</p></div></div>

<div class="footdef"><sup><a id="fn.5" class="footnum" href="#fnr.5">5</a></sup> <div class="footpara"><p class="footpara">
periodica.
</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="date">Data: 2021-11-03 mer 00:00</p>
<p class="author">Autore: Alessandro Straziota</p>
<p class="email">Email: <a href="mailto:alessandrostr95@gmail.com">alessandrostr95@gmail.com</a></p>
<p class="date">Created: 2021-11-17 mer 00:39</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
